{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Luis Antonio Ortega Andrés     \n",
    "Antonio Coín Castro*\n",
    "\n",
    "# Métodos Avanzados en Aprendizaje Automático \n",
    "# Práctica 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo de Eliminación de Variables\n",
    "\n",
    "Este algoritmo se utiliza para hacer inferencia en redes. Supongamos que tenemos la factorización de una distribución conjunta \n",
    "\n",
    "$$ P(\\mathbf{X}) = P(X_1, X_2, \\dots, X_N) = \\prod_{i=1}^N P(X_i|Par(X_i))$$ \n",
    "\n",
    "y una evidenica $ \\mathbf{Z}=\\mathbf{z} $, donde $\\mathbf{Z} \\subset \\mathbf{X}$ es un subconjunto de las variables del problema y $\\mathbf{z}$ son sus valores observados. El objetivo es obtener la distribución de parte de las variables del problema, $\\mathbf{W} \\subset \\mathbf{X}$, dada la evidencia $\\mathbf{Z}=\\mathbf{z}$. Es decir, queremos obtener $P(\\mathbf{W}|\\mathbf{Z}=\\mathbf{z})$. Para ello debemos:\n",
    "\n",
    "* Reducir los factores que incluyan $\\mathbf{Z}$.\n",
    "* Eliminar el resto de variables no incluidas $\\mathbf{W}$.\n",
    "\n",
    "$$ P(\\mathbf{W}|\\mathbf{Z}=\\mathbf{z}) = \\sum_{X \\setminus (W\\cup Z)} \\frac{P(\\mathbf{X}\\setminus \\mathbf{Z},\\mathbf{Z}=\\mathbf{z})}{P(\\mathbf{Z}=\\mathbf{z})} \\propto \\sum_{X \\setminus (W\\cup Z)} P(\\mathbf{X}\\setminus \\mathbf{Z},\\mathbf{Z}=\\mathbf{z}).$$\n",
    "\n",
    "\n",
    "Algoritmo de eliminación de variables esquemático para un conjunto de factores $\\mathbf{\\Phi}=\\{\\Phi_1,\\dots,\\Phi_N\\}$:\n",
    "1.  Reducir todos los factores que contengan alguna variable de $\\mathbf{Z}$ en su dominio, usando la evidencia dada $\\mathbf{Z}=\\mathbf{z}$.\n",
    "2.  Para cada variable X en $\\mathbf{X} \\setminus (\\mathbf{W} \\cup \\mathbf{Z})$, eliminar la variable X mediante marginalización:\n",
    "    1. Hacer el producto de todos los factores que tienen X en su dominio: $\\psi = \\prod_{i \\mid X\\in Dom(\\Phi_i) }\\Phi_i$. \n",
    "    2. Marginalizar X del factor producto obtenido en A: $\\tau = \\sum_X \\psi$.\n",
    "    3. Actualizar la lista de factores quitando los factores que incluyen X y añadiendo el factor marginalizado $\\tau$: $\\mathbf{\\Phi} = (\\mathbf{\\Phi} \\setminus {\\psi}) \\cup \\tau$.\n",
    "3. Multiplicar factores restantes.\n",
    "4. Renormalizar para obtener una distribución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una clase para representar una red bayesiana a partir de la factorización de la distribución conjunta. Nos ayudamos de una serie de funciones auxiliares para normalizar, marginalizar y reducir factores, e implementamos un método para aplicar el algoritmo de eliminación de variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianNetwork:\n",
    "    \"\"\"\n",
    "    Represents a Bayesian Network via its joint distribution decomposition.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, factor_list):\n",
    "        \"\"\" Construct a network from its factorization. Every factor must have the same\n",
    "            number of dimensions, which coincides with the total number of variables.\"\"\"\n",
    "        \n",
    "        self.factor_list = factor_list\n",
    "        self.variables = np.arange(len(self.factor_list))\n",
    "\n",
    "    def _normalize(self, distribution):\n",
    "        \"\"\" Normalize a distribution so that all values add up to 1. \"\"\"\n",
    "\n",
    "        return distribution / np.sum(distribution)\n",
    "\n",
    "    def _marginal(self, distribution, variables):\n",
    "        \"\"\" Marginalize a distribution for the given list of (indices of) variables. \"\"\"\n",
    "\n",
    "        return np.sum(distribution, axis = tuple(variables), keepdims = True)\n",
    "\n",
    "    def _reduce(self, distribution, variables, asignments, normalize_output = True):\n",
    "        \"\"\" This function receives a distribution, \n",
    "            a list of indices to variables and \n",
    "            a list of assignments to those variables.\n",
    "            \n",
    "            It performs reduction on the specified variables with the given assignments. \"\"\"\n",
    "\n",
    "        reduced = distribution.copy()\n",
    "        for variable, asignment in zip(variables, asignments):\n",
    "            reduced = np.swapaxes(reduced, 0, variable)[[asignment]]\n",
    "            reduced = np.swapaxes(reduced, 0, variable)\n",
    "\n",
    "        return normalize(reduced) if normalize_output else reduced\n",
    "    \n",
    "    def _factor_has_var(self, factor, variable):\n",
    "        \"\"\" Return whether a given factor has a specific variable on its domain. \"\"\"\n",
    "\n",
    "        return factor.shape[variable] > 1\n",
    "\n",
    "    def _multi_prod(self, arrays):\n",
    "        \"\"\" Perform the element-wise product of multiple arrays. \"\"\"\n",
    "        \n",
    "        assert(len(arrays) > 0)\n",
    "\n",
    "        res = arrays[0]\n",
    "        for arr in arrays[1:]:\n",
    "            res = res * arr\n",
    "\n",
    "        return res\n",
    "\n",
    "    def VE(self, W, Zs = [], zs = [], order = []):\n",
    "        \"\"\" Implement the variable elimination algorithm.\n",
    "\n",
    "            Input:\n",
    "                * W:       list of desired variables in the output factor.\n",
    "                * Zs:      list with the observed variables.\n",
    "                * zs:      list with the values of the observed variables.\n",
    "                * order:   order in which the variables not in (W U Zs) are processed. \n",
    "                           If empty, an ascending order is assumed. If not empty, the indices\n",
    "                           must be relative to the ones in self.factor_list.\n",
    "            \n",
    "            Ouput:\n",
    "                * Factor representing the joint distribution P(W|Zs=zs).\n",
    "                * The size of the biggest factor processed.\n",
    "        \"\"\"\n",
    "        \n",
    "        factors = self.factor_list.copy()\n",
    "        variables_factors = np.arange(len(factors))\n",
    "\n",
    "        # -- STEP 1: reduce factors that contain any variable in Zs --\n",
    "        for Z, z in zip(Zs, zs):\n",
    "            for i, factor in enumerate(factors):\n",
    "                if self._factor_has_var(factor, Z):\n",
    "                    factors[i] = self._reduce(factor, [Z], [z], False)\n",
    "\n",
    "        # -- STEP 2: eliminate variables via marginalization --\n",
    "        variables_rest = np.setdiff1d(variables_factors, np.union1d(W, Zs))\n",
    "        \n",
    "        # Take the desired ordering into account\n",
    "        if len(order) > 0:\n",
    "            assert((np.unique(order) == np.unique(variables_rest)).all() \n",
    "                     and len(order) == len(variables_rest))\n",
    "            variables_rest = order\n",
    "            \n",
    "        # Process each variable in order\n",
    "        max_size = 0\n",
    "        for X in variables_rest:\n",
    "            # Recover the indices of factors that have X on their domain\n",
    "            factors_X_idx = [i for i in variables_factors if self._factor_has_var(factors[i], X)]\n",
    "            \n",
    "            # Multiply those factors together\n",
    "            psi = self._multi_prod([factors[i] for i in factors_X_idx])\n",
    "            \n",
    "            # Marginalize the product with respect to X\n",
    "            tau = self._marginal(psi, [X])\n",
    "            \n",
    "            # Update the factor list\n",
    "            factors = [factors[i] for i in np.setdiff1d(variables_factors, factors_X_idx)] + [tau]\n",
    "            variables_factors = np.arange(len(factors))\n",
    "            \n",
    "            # Compute size of the processed factor\n",
    "            max_size = max(max_size, np.prod(psi.shape))\n",
    "\n",
    "        # -- STEPS 3 and 4: multiply the remaining factors and normalize --\n",
    "        res = self._normalize(self._multi_prod([*factors]))\n",
    "        \n",
    "        return res, max_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una distribución para probar el algoritmo, basándonos en el siguiente grafo:\n",
    "\n",
    "![estu](img/estu2.png)\n",
    "\n",
    "Las variables representadas son:\n",
    "\n",
    "* **Nota examen (G)**: g0 (sobresaliente), g1 (notable), g2 (aprobado).\n",
    "* **Dificultad examen (D)**: d0 (fácil) y d1 (difícil).\n",
    "* **Inteligencia (I)**: i0 (normal), i1 (alta).\n",
    "* **Nota Selectividad (S)**: s0 (baja), s1 (alta).\n",
    "* **Carta de recomendación (L)**: l0 (regular), l1 (buena).\n",
    "\n",
    "La distribución conjunta es entonces:\n",
    "\n",
    "$$P(I,D, G,L,S) = P(I)P(D)P(G|I,D)P(L|G)P(S|I).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensión -> 0  1  2  3  4\n",
    "# Variable  -> I  D  G  L  S\n",
    "\n",
    "PI = np.array([0.7, 0.3]).reshape((2, 1, 1, 1, 1))\n",
    "PD = np.array([0.6, 0.4]).reshape((1, 2, 1, 1, 1))\n",
    "PG_ID = np.array([0.3, 0.4, 0.3, 0.05, 0.25, 0.7, 0.9, 0.08, 0.02, 0.5, 0.3, 0.2]).reshape((2, 2, 3, 1, 1))\n",
    "PL_G = np.array([0.1, 0.9, 0.4, 0.6, 0.99, 0.01]).reshape((1, 1, 3, 2, 1))\n",
    "PS_I = np.array([0.95, 0.05, 0.2, 0.8]).reshape((2, 1, 1, 1, 2))\n",
    "\n",
    "# Distribución conjunta\n",
    "PIDGLS = PI * PD * PG_ID * PL_G* PS_I\n",
    "\n",
    "# Red bayesiana\n",
    "network = BayesianNetwork([PI, PD, PG_ID, PL_G, PS_I])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos una serie de casos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos los casos de prueba son correctos.\n"
     ]
    }
   ],
   "source": [
    "# ¿Cuál es la distribución P(I)?\n",
    "factor, max_size = network.VE([0])\n",
    "assert(np.allclose(np.array([[[[[0.7]]]], [[[[0.3]]]]]), factor))\n",
    "assert(max_size == 12)\n",
    "\n",
    "# Si sabemos que la nota del examen es aprobado, ¿cuál es la distribución de la inteligencia? \n",
    "# P(I|G=g2)\n",
    "factor, max_size = network.VE([0], [2], [2])\n",
    "assert(np.allclose(np.array([[[[[0.92105263]]]], [[[[0.07894737]]]]]), factor))\n",
    "assert(max_size == 4)\n",
    "\n",
    "# Y si además el examen es difícil?\n",
    "# P(I|G=g2,D=d1)\n",
    "factor, max_size = network.VE([0], [1,2], [1,2])\n",
    "assert(np.allclose(np.array([[[[[0.89090909]]]], [[[[0.10909091]]]]]), factor))\n",
    "assert(max_size == 4)\n",
    "\n",
    "print(\"Todos los casos de prueba son correctos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos los casos de prueba son correctos.\n"
     ]
    }
   ],
   "source": [
    "# Calcula la distribución P(D)\n",
    "factor, max_size = network.VE([1])\n",
    "assert(np.allclose(np.array([[[[[0.6]]], [[[0.4]]]]]), factor))\n",
    "assert(max_size == 24)\n",
    "\n",
    "# Prob examen si nota es aprobado: P(D|G=g2)\n",
    "factor, max_size = network.VE([1], [2], [2])\n",
    "assert(np.allclose(np.array([[[[[0.37070938]]], [[[0.62929062]]]]]), factor))\n",
    "assert(max_size == 8)\n",
    "\n",
    "# Probabilidad de examen difícil D=d1 dado que G=g2 y S=s1\n",
    "factor, max_size = network.VE([1], [2,4], [2,1])\n",
    "assert(np.allclose(np.array([[[[[0.24044002]]], [[[0.75955998]]]]]), factor))\n",
    "assert(max_size == 4)\n",
    "\n",
    "print(\"Todos los casos de prueba son correctos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente estudiamos cómo influyen unas variables sobre otras, dependiendo de la evidencia que tengamos. En concreto, nos preguntamos si la nota de selectividad (S) influye en la dificultad del examen (D), dependiendo de si conocemos o no su nota (G)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de D:\n",
      " [[[[[0.6]]]\n",
      "\n",
      "\n",
      "  [[[0.4]]]]]\n",
      "\n",
      "Distribución de D|S=1:\n",
      " [[[[[0.6]]]\n",
      "\n",
      "\n",
      "  [[[0.4]]]]]\n",
      "--> No cambia\n",
      "\n",
      "Distribución de D|G=2:\n",
      " [[[[[0.37070938]]]\n",
      "\n",
      "\n",
      "  [[[0.62929062]]]]]\n",
      "--> Cambia\n",
      "\n",
      "Distribución de D|G=2,S=1:\n",
      " [[[[[0.24044002]]]\n",
      "\n",
      "\n",
      "  [[[0.75955998]]]]]\n",
      "--> Cambia\n"
     ]
    }
   ],
   "source": [
    "# P(D)\n",
    "pd, _ = network.VE([1])\n",
    "print(\"Distribución de D:\\n\", pd)\n",
    "\n",
    "# P(D|S=1), no conocemos G\n",
    "pd_s1, _ = network.VE([1], [4], [1])\n",
    "print(\"\\nDistribución de D|S=1:\\n\", pd_s1)\n",
    "if np.allclose(pd_s1, pd):\n",
    "    print(\"--> No cambia\")\n",
    "else:\n",
    "    print(\"--> Cambia\")\n",
    "\n",
    "# P(D|G=2)\n",
    "pd_g2, _ = network.VE([1], [2], [2])\n",
    "print(\"\\nDistribución de D|G=2:\\n\", pd_g2)\n",
    "if np.allclose(pd_g2, pd):\n",
    "    print(\"--> No cambia\")\n",
    "else:\n",
    "    print(\"--> Cambia\")\n",
    "\n",
    "# P(D|G=2,S=1), conocemos G\n",
    "pd_g2s1, _ = network.VE([1], [2, 4], [2, 1])\n",
    "print(\"\\nDistribución de D|G=2,S=1:\\n\", pd_g2s1)\n",
    "if np.allclose(pd_g2s1, pd):\n",
    "    print(\"--> No cambia\")\n",
    "else:\n",
    "    print(\"--> Cambia\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
