{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Luis Antonio Ortega Andrés     \n",
    "Antonio Coín Castro*\n",
    "\n",
    "# Métodos Avanzados en Aprendizaje Automático \n",
    "# Práctica 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo de Eliminación de Variables\n",
    "\n",
    "Este algoritmo se utiliza para hacer inferencia en redes. Supongamos que tenemos la factorización de una distribución conjunta \n",
    "\n",
    "$$ P(\\mathbf{X}) = P(X_1, X_2, \\dots, X_N) = \\prod_{i=1}^N P(X_i|Par(X_i))$$ \n",
    "\n",
    "y una evidenica $ \\mathbf{Z}=\\mathbf{z} $, donde $\\mathbf{Z} \\subset \\mathbf{X}$ es un subconjunto de las variables del problema y $\\mathbf{z}$ son sus valores observados. El objetivo es obtener la distribución de parte de las variables del problema, $\\mathbf{W} \\subset \\mathbf{X}$, dada la evidencia $\\mathbf{Z}=\\mathbf{z}$. Es decir, queremos obtener $P(\\mathbf{W}|\\mathbf{Z}=\\mathbf{z})$. Para ello debemos:\n",
    "\n",
    "* Reducir los factores que incluyan $\\mathbf{Z}$.\n",
    "* Eliminar el resto de variables no incluidas $\\mathbf{W}$.\n",
    "\n",
    "$$ P(\\mathbf{W}|\\mathbf{Z}=\\mathbf{z}) = \\sum_{X \\setminus (W\\cup Z)} \\frac{P(\\mathbf{X}\\setminus \\mathbf{Z},\\mathbf{Z}=\\mathbf{z})}{P(\\mathbf{Z}=\\mathbf{z})} \\propto \\sum_{X \\setminus (W\\cup Z)} P(\\mathbf{X}\\setminus \\mathbf{Z},\\mathbf{Z}=\\mathbf{z}).$$\n",
    "\n",
    "\n",
    "Algoritmo de eliminación de variables esquemático para un conjunto de factores $\\mathbf{\\Phi}=\\{\\Phi_1,\\dots,\\Phi_N\\}$:\n",
    "1.  Reducir todos los factores que contengan alguna variable de $\\mathbf{Z}$ en su dominio, usando la evidencia dada $\\mathbf{Z}=\\mathbf{z}$.\n",
    "2.  Para cada variable X en $\\mathbf{X} \\setminus (\\mathbf{W} \\cup \\mathbf{Z})$, eliminar la variable X mediante marginalización:\n",
    "    1. Hacer el producto de todos los factores que tienen X en su dominio: $\\psi = \\prod_{i \\mid X\\in Dom(\\Phi_i) }\\Phi_i$. \n",
    "    2. Marginalizar X del factor producto obtenido en A: $\\tau = \\sum_X \\psi$.\n",
    "    3. Actualizar la lista de factores quitando los factores que incluyen X y añadiendo el factor marginalizado $\\tau$: $\\mathbf{\\Phi} = (\\mathbf{\\Phi} \\setminus {\\psi}) \\cup \\tau$.\n",
    "3. Multiplicar factores restantes.\n",
    "4. Renormalizar para obtener una distribución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_has_any_var(factor, variables):\n",
    "    \"\"\" Return wheter a given factor has any of the variables listed on its domain. \"\"\"\n",
    "    \n",
    "    return any([factor.shape[v] > 1 for v in variables])\n",
    "    \n",
    "def VA(factor_list, W, Zs=[], zs=[], order=[]):\n",
    "    \"\"\" Implementar variable elimination algorithm\n",
    "    \n",
    "        Entrada:\n",
    "           * factor_list: lista con los factores a procesar\n",
    "           * W:           lista de variables en el factor de salida\n",
    "           * Zs:          lista de variables observadas\n",
    "           * zs:          lista de valores de las variables observadas\n",
    "           * order:       orden en que se procesan las variables. Si no se \n",
    "                          indica nada se hacer en orden ascendente\n",
    "        Salida:\n",
    "           * Factor con la distribucion conjunta W dada la evidencia\n",
    "           * El tamaño del factor más grande que se procese\n",
    "        \n",
    "    \"\"\"\n",
    "        \n",
    "    for Z, z in zip(Zs, zs):\n",
    "        for i, factor in enumerate(factor_list):\n",
    "            if factor_has_any_var(factor, [Z]):\n",
    "                factor = reduce()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una distribución para probar el algoritmo, basándonos en el siguiente grafo:\n",
    "\n",
    "![estu](img/estu2.png)\n",
    "\n",
    "Las variables representadas son:\n",
    "\n",
    "* **Nota examen (G)**: g0 (sobresaliente), g1 (notable), g2 (aprobado).\n",
    "* **Dificultad examen (D)**: d0 (fácil) y d1 (difícil).\n",
    "* **Inteligencia (I)**: i0 (normal), i1 (alta).\n",
    "* **Nota Selectividad (S)**: s0 (baja), s1 (alta).\n",
    "* **Carta de recomendación (L)**: l0 (regular), l1 (buena).\n",
    "\n",
    "La distribución conjunta es entonces:\n",
    "\n",
    "$$P(I,D, G,L,S) = P(I)P(D)P(G|I,D)P(L|G)P(S|I).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensión -> 0  1  2  3  4\n",
    "# Variable  -> I, D, G, L, S\n",
    "\n",
    "PI = np.array([0.7, 0.3]).reshape((2,1,1,1,1))\n",
    "PD = np.array([0.6, 0.4]).reshape((1,2,1,1,1))\n",
    "PG_ID = np.array([0.3, 0.4, 0.3, 0.05, 0.25, 0.7, 0.9, 0.08, 0.02, 0.5, 0.3, 0.2]).reshape((2,2,3,1,1))\n",
    "PL_G = np.array([0.1, 0.9, 0.4, 0.6, 0.99, 0.01]).reshape((1,1,3,2,1))\n",
    "PS_I = np.array([0.95, 0.05, 0.2, 0.8]).reshape((2,1,1,1,2))\n",
    "\n",
    "# Distribución conjunta\n",
    "PIDGLS = PI * PD * PG_ID * PL_G* PS_I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos una serie de casos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula la distribución P(I)\n",
    "factor, maxsize = VA([PI, PD, PG_ID, PL_G, PS_I],[0])\n",
    "assert(np.allclose(np.array([[[[[0.7]]]],[[[[0.3]]]]]),factor))\n",
    "assert(maxsize==12)\n",
    "print(PI)\n",
    "\n",
    "# Si sabemos que la nota del examen es aprobado, ¿Cuál es la prob de inteligencia? \n",
    "# P(I|G=g2)\n",
    "factor, maxsize = VA([PI, PD, PG_ID, PL_G, PS_I],[0],[2],[2])\n",
    "assert(np.allclose(np.array([[[[[0.92105263]]]],[[[[0.07894737]]]]]), factor))\n",
    "assert(maxsize==4)\n",
    "\n",
    "# y si además el examen es difícil\n",
    "# P(I|G=g2,D=d1)\n",
    "factor, maxsize = VA([PI, PD, PG_ID, PL_G, PS_I],[0],[1,2],[1,2])\n",
    "assert(np.allclose(np.array([[[[[0.89090909]]]],[[[[0.10909091]]]]]), factor))\n",
    "assert(maxsize==4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prob examen: Calcula la distribución: P(D)\n",
    "factor, maxsize = VA([PI, PD, PG_ID, PL_G, PS_I],[1])\n",
    "assert(np.allclose(np.array([[[[[0.6]]],[[[0.4]]]]]),factor))\n",
    "assert(maxsize==24)\n",
    "\n",
    "# Prob examen | nota aprobado: P(D|G=g2)\n",
    "factor, maxsize = VA([PI, PD, PG_ID, PL_G, PS_I],[1],[2],[2])\n",
    "assert(np.allclose(np.array([[[[[0.37070938]]],[[[0.62929062]]]]]),factor))\n",
    "assert(maxsize==8)\n",
    "\n",
    "# Probabilidad de examen difícil D=d1|G=g2,S=s1?\n",
    "factor, maxsize = VA([PI, PD, PG_ID, PL_G, PS_I],[1],[2,4],[2,1])\n",
    "assert(np.allclose(np.array([[[[[0.24044002]]],[[[0.75955998]]]]]),factor))\n",
    "assert(maxsize==4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si no se conoce G, ¿Influye la nota de selectividad en la dificultad del examen?\n",
    "# dif examen\n",
    "print(VA([PI, PD, PG_ID, PL_G, PS_I],[1]))\n",
    "\n",
    "# dif examen si sat=1\n",
    "print(VA([PI, PD, PG_ID, PL_G, PS_I],[1],[4],[1])) # No cambia\n",
    "\n",
    "# Ahora sabiendo que nota es aprobado\n",
    "print(VA([PI, PD, PG_ID, PL_G, PS_I],[1],[2],[2])) \n",
    "print(VA([PI, PD, PG_ID, PL_G, PS_I],[1],[2,4],[2,1])) # Sí cambia"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
