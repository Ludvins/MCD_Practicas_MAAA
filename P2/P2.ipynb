{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Luis Antonio Ortega Andrés     \n",
    "Antonio Coín Castro*\n",
    "\n",
    "# Métodos Avanzados en Aprendizaje Automático \n",
    "# Práctica 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo de Eliminación de Variables\n",
    "\n",
    "Este algoritmo se utiliza para hacer inferencia en redes. Supongamos que tenemos la factorización de una distribución conjunta \n",
    "\n",
    "$$ P(\\mathbf{X}) = P(X_1, X_2, \\dots, X_N) = \\prod_{i=1}^N P(X_i|Par(X_i))$$ \n",
    "\n",
    "y una evidenica $ \\mathbf{Z}=\\mathbf{z} $, donde $\\mathbf{Z} \\subset \\mathbf{X}$ es un subconjunto de las variables del problema y $\\mathbf{z}$ son sus valores observados. El objetivo es obtener la distribución de parte de las variables del problema, $\\mathbf{W} \\subset \\mathbf{X}$, dada la evidencia $\\mathbf{Z}=\\mathbf{z}$. Es decir, queremos obtener $P(\\mathbf{W}|\\mathbf{Z}=\\mathbf{z})$. Para ello debemos:\n",
    "\n",
    "* Reducir los factores que incluyan $\\mathbf{Z}$.\n",
    "* Eliminar el resto de variables no incluidas $\\mathbf{W}$.\n",
    "\n",
    "$$ P(\\mathbf{W}|\\mathbf{Z}=\\mathbf{z}) = \\sum_{X \\setminus (W\\cup Z)} \\frac{P(\\mathbf{X}\\setminus \\mathbf{Z},\\mathbf{Z}=\\mathbf{z})}{P(\\mathbf{Z}=\\mathbf{z})} \\propto \\sum_{X \\setminus (W\\cup Z)} P(\\mathbf{X}\\setminus \\mathbf{Z},\\mathbf{Z}=\\mathbf{z}).$$\n",
    "\n",
    "\n",
    "Algoritmo de eliminación de variables esquemático para un conjunto de factores $\\mathbf{\\Phi}=\\{\\Phi_1,\\dots,\\Phi_N\\}$:\n",
    "1.  Reducir todos los factores que contengan alguna variable de $\\mathbf{Z}$ en su dominio, usando la evidencia dada $\\mathbf{Z}=\\mathbf{z}$.\n",
    "2.  Para cada variable X en $\\mathbf{X} \\setminus (\\mathbf{W} \\cup \\mathbf{Z})$, eliminar la variable X mediante marginalización:\n",
    "    1. Hacer el producto de todos los factores que tienen X en su dominio: $\\psi = \\prod_{i \\mid X\\in Dom(\\Phi_i) }\\Phi_i$. \n",
    "    2. Marginalizar X del factor producto obtenido en A: $\\tau = \\sum_X \\psi$.\n",
    "    3. Actualizar la lista de factores quitando los factores que incluyen X y añadiendo el factor marginalizado $\\tau$: $\\mathbf{\\Phi} = (\\mathbf{\\Phi} \\setminus {\\psi}) \\cup \\tau$.\n",
    "3. Multiplicar factores restantes.\n",
    "4. Renormalizar para obtener una distribución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar definimos una serie de funciones auxiliares para normalizar, marginalizar y reducir factores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(distribution):\n",
    "    \"\"\" Normalizes the distribution so that all values add up to 1\"\"\"\n",
    "    \n",
    "    return distribution/np.sum(distribution)\n",
    "\n",
    "def marginal(distribution, variables):\n",
    "    \"\"\" Marginalizes the distributions for the given list of variables \"\"\"\n",
    "    \n",
    "    dd = distribution\n",
    "    \n",
    "    for variable in variables:\n",
    "        dd = np.sum(dd, axis=variable, keepdims=True)\n",
    "        \n",
    "    return dd\n",
    "\n",
    "def reduce(distribution, variables, asignments, normalize_output=True):\n",
    "    \"\"\" This function receives a distribution, \n",
    "        a list of indices to variables and \n",
    "        a list of the assignements to those variables \"\"\"\n",
    "    \n",
    "    reduced = distribution.copy()\n",
    "\n",
    "    for variable, asignment in zip(variables,asignments):\n",
    "        reduced = np.swapaxes(reduced, 0, variable)[[asignment]]\n",
    "        reduced = np.swapaxes(reduced, 0, variable)\n",
    "        \n",
    "    return normalize(reduced) if normalize_output else reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_has_var(factor, variable):\n",
    "    \"\"\" Return wheter a given factor has a specific variables on its domain. \"\"\"\n",
    "\n",
    "    return factor.shape[variable] > 1\n",
    "\n",
    "def multi_prod(arrays):\n",
    "    assert(len(arrays)>0)\n",
    "    \n",
    "    res = arrays[0]\n",
    "    for arr in arrays[1:]:\n",
    "        res = res * arr\n",
    "        \n",
    "    return res\n",
    "    \n",
    "def VA(factor_list, W, Zs=[], zs=[], order=[]):\n",
    "    \"\"\" Implementar variable elimination algorithm\n",
    "    \n",
    "        Entrada:\n",
    "           * factor_list: lista con los factores a procesar\n",
    "           * W:           lista de variables en el factor de salida\n",
    "           * Zs:          lista de variables observadas\n",
    "           * zs:          lista de valores de las variables observadas\n",
    "           * order:       orden en que se procesan las variables. Si no se \n",
    "                          indica nada se hacer en orden ascendente. Si se indica,\n",
    "                          los índices deben coincidir con los de X \\ (W U Z).\n",
    "        Salida:\n",
    "           * Factor con la distribucion conjunta W dada la evidencia\n",
    "           * El tamaño del factor más grande que se procese\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Paso 1: reducir factores que contengan alguna variable de Z\n",
    "    factors = factor_list.copy()\n",
    "    variables = np.arange(len(factors))\n",
    "    for Z,z in zip(Zs, zs):\n",
    "        for i, factor in enumerate(factors):\n",
    "            if factor_has_var(factor, Z):\n",
    "                factors[i] = reduce(factor, [Z], [z], False)\n",
    "    \n",
    "    # Paso 2: eliminar variables de la sumatoria mediante marginalización\n",
    "    variables_rest = np.setdiff1d(variables, np.union1d(W, Zs))\n",
    "    if len(order)>0:\n",
    "        assert((np.unique(order) == np.unique(variables_rest)).all() and len(order)==len(variables_rest))\n",
    "        variables_rest = order\n",
    "        \n",
    "    max_size = 0\n",
    "    for X in variables_rest:\n",
    "        factors_X_idx = [i for i in variables if factor_has_var(factors[i], X)]\n",
    "        psi = multi_prod([factors[i] for i in factors_X_idx])\n",
    "        tau = marginal(psi, [X])\n",
    "        factors = [factors[i] for i in np.setdiff1d(variables, factors_X_idx)] + [tau]\n",
    "        variables = np.arange(len(factors))\n",
    "        max_size = max(max_size, np.prod(psi.shape))\n",
    "\n",
    "    # Pasos 3 y 4: multiplicar los factores restantes y normalizar\n",
    "    return normalize(multi_prod([factors[i] for i in variables])), max_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una distribución para probar el algoritmo, basándonos en el siguiente grafo:\n",
    "\n",
    "![estu](img/estu2.png)\n",
    "\n",
    "Las variables representadas son:\n",
    "\n",
    "* **Nota examen (G)**: g0 (sobresaliente), g1 (notable), g2 (aprobado).\n",
    "* **Dificultad examen (D)**: d0 (fácil) y d1 (difícil).\n",
    "* **Inteligencia (I)**: i0 (normal), i1 (alta).\n",
    "* **Nota Selectividad (S)**: s0 (baja), s1 (alta).\n",
    "* **Carta de recomendación (L)**: l0 (regular), l1 (buena).\n",
    "\n",
    "La distribución conjunta es entonces:\n",
    "\n",
    "$$P(I,D, G,L,S) = P(I)P(D)P(G|I,D)P(L|G)P(S|I).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensión -> 0  1  2  3  4\n",
    "# Variable  -> I, D, G, L, S\n",
    "\n",
    "PI = np.array([0.7, 0.3]).reshape((2,1,1,1,1))\n",
    "PD = np.array([0.6, 0.4]).reshape((1,2,1,1,1))\n",
    "PG_ID = np.array([0.3, 0.4, 0.3, 0.05, 0.25, 0.7, 0.9, 0.08, 0.02, 0.5, 0.3, 0.2]).reshape((2,2,3,1,1))\n",
    "PL_G = np.array([0.1, 0.9, 0.4, 0.6, 0.99, 0.01]).reshape((1,1,3,2,1))\n",
    "PS_I = np.array([0.95, 0.05, 0.2, 0.8]).reshape((2,1,1,1,2))\n",
    "\n",
    "# Distribución conjunta\n",
    "PIDGLS = PI * PD * PG_ID * PL_G* PS_I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos una serie de casos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula la distribución P(I)\n",
    "factor, maxsize = VA([PI, PD, PG_ID, PL_G, PS_I],[0])\n",
    "assert(np.allclose(np.array([[[[[0.7]]]],[[[[0.3]]]]]),factor))\n",
    "assert(maxsize==12)\n",
    "\n",
    "# Si sabemos que la nota del examen es aprobado, ¿Cuál es la prob de inteligencia? \n",
    "# P(I|G=g2)\n",
    "factor, maxsize = VA([PI, PD, PG_ID, PL_G, PS_I],[0],[2],[2])\n",
    "assert(np.allclose(np.array([[[[[0.92105263]]]],[[[[0.07894737]]]]]), factor))\n",
    "assert(maxsize==4)\n",
    "\n",
    "# y si además el examen es difícil\n",
    "# P(I|G=g2,D=d1)\n",
    "factor, maxsize = VA([PI, PD, PG_ID, PL_G, PS_I],[0],[1,2],[1,2])\n",
    "assert(np.allclose(np.array([[[[[0.89090909]]]],[[[[0.10909091]]]]]), factor))\n",
    "assert(maxsize==4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prob examen: Calcula la distribución: P(D)\n",
    "factor, maxsize = VA([PI, PD, PG_ID, PL_G, PS_I],[1])\n",
    "assert(np.allclose(np.array([[[[[0.6]]],[[[0.4]]]]]),factor))\n",
    "assert(maxsize==24)\n",
    "\n",
    "# Prob examen | nota aprobado: P(D|G=g2)\n",
    "factor, maxsize = VA([PI, PD, PG_ID, PL_G, PS_I],[1],[2],[2])\n",
    "assert(np.allclose(np.array([[[[[0.37070938]]],[[[0.62929062]]]]]),factor))\n",
    "assert(maxsize==8)\n",
    "\n",
    "# Probabilidad de examen difícil D=d1|G=g2,S=s1?\n",
    "factor, maxsize = VA([PI, PD, PG_ID, PL_G, PS_I],[1],[2,4],[2,1])\n",
    "assert(np.allclose(np.array([[[[[0.24044002]]],[[[0.75955998]]]]]),factor))\n",
    "assert(maxsize==4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[[[0.6]]],\n",
      "\n",
      "\n",
      "        [[[0.4]]]]]), 24)\n",
      "(array([[[[[0.6]]],\n",
      "\n",
      "\n",
      "        [[[0.4]]]]]), 12)\n",
      "(array([[[[[0.37070938]]],\n",
      "\n",
      "\n",
      "        [[[0.62929062]]]]]), 8)\n",
      "(array([[[[[0.24044002]]],\n",
      "\n",
      "\n",
      "        [[[0.75955998]]]]]), 4)\n"
     ]
    }
   ],
   "source": [
    "# Si no se conoce G, ¿Influye la nota de selectividad en la dificultad del examen?\n",
    "# dif examen\n",
    "print(VA([PI, PD, PG_ID, PL_G, PS_I],[1]))\n",
    "\n",
    "# dif examen si sat=1\n",
    "print(VA([PI, PD, PG_ID, PL_G, PS_I],[1],[4],[1])) # No cambia\n",
    "\n",
    "# Ahora sabiendo que nota es aprobado\n",
    "print(VA([PI, PD, PG_ID, PL_G, PS_I],[1],[2],[2])) # Sí cambia\n",
    "\n",
    "# Ahora sabiendo que nota es aprobado y sat=1\n",
    "print(VA([PI, PD, PG_ID, PL_G, PS_I],[1],[2,4],[2,1])) # Sí cambia"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
