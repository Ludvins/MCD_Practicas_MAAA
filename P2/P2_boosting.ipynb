{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Luis Antonio Ortega Andrés    \n",
    "Antonio Coín Castro*\n",
    "# Métodos Avanzados en Aprendizaje Automático"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T15:36:50.819579Z",
     "start_time": "2020-11-12T15:36:50.805327Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:04:31.371624Z",
     "start_time": "2020-11-17T11:04:31.356960Z"
    }
   },
   "outputs": [],
   "source": [
    "def plotModel(x,y,clase,clf,title=\"\"):\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    \n",
    "    x_min, x_max = x.min() - .2, x.max() + .2\n",
    "    y_min, y_max = y.min() - .2, y.max() + .2\n",
    "    hx = (x_max - x_min)/100.\n",
    "    hy = (y_max - y_min)/100.\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, hx), np.arange(y_min, y_max, hy))\n",
    "\n",
    "    if hasattr(clf, \"decision_function\"):\n",
    "        z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "    elif hasattr(clf, \"predict_proba\"):\n",
    "        z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "    else:\n",
    "        z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    z = z.reshape(xx.shape)\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    \n",
    "    plt.contourf(xx, yy, z, cmap=cm, alpha=.8)\n",
    "    plt.contour(xx, yy, z, [0.5], linewidths=[2], colors=['k'])\n",
    "\n",
    "    if clase is not None:\n",
    "        plt.scatter(x[clase==-1], y[clase==-1], c='#FF0000')\n",
    "        plt.scatter(x[clase==1], y[clase==1], c='#0000FF')\n",
    "    else:\n",
    "        plt.plot(x,y,'g', linewidth=3)\n",
    "        \n",
    "    plt.gca().set_xlim(xx.min(), xx.max())\n",
    "    plt.gca().set_ylim(yy.min(), yy.max())\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T15:33:22.700631Z",
     "start_time": "2020-11-12T15:33:22.657613Z"
    }
   },
   "outputs": [],
   "source": [
    "def createDataSet(n, model, ymargin, noise=None, output_boundary=False):\n",
    "    x = np.random.rand(n,1)*2.0*np.pi\n",
    "    xbnd = np.linspace(0,2.0*np.pi,100)\n",
    "\n",
    "    if model == 'sine':\n",
    "        y = (np.random.rand(n,1) - 0.5)*2.2\n",
    "        c = y > np.sin(x)\n",
    "        ybnd = np.sin(xbnd)\n",
    "    elif model == 'linear':\n",
    "        y = np.random.rand(n,1)*2.0*np.pi\n",
    "        c = y > x\n",
    "        ybnd = xbnd\n",
    "    elif model == 'square':\n",
    "        y = np.random.rand(n,1)*4.0*np.pi*np.pi\n",
    "        c = y > x*x\n",
    "        ybnd = xbnd*xbnd\n",
    "    else:\n",
    "        y = np.random.rand(n,1)*2.0*np.pi\n",
    "        c = y > x\n",
    "        ybnd = xbnd\n",
    "    \n",
    "    y[c == True] = y[c == True] + ymargin\n",
    "    y[c == False] = y[c == False] - ymargin\n",
    "    \n",
    "    if noise is not None:\n",
    "        y = y + noise * np.random.randn(n,1)\n",
    "        x = x + noise * np.random.randn(n,1)\n",
    "\n",
    "    if output_boundary == True:\n",
    "        return x, y, (c*1).ravel(), xbnd, ybnd\n",
    "    else:\n",
    "        return x, y, (c*1).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T15:33:23.248924Z",
     "start_time": "2020-11-12T15:33:23.233703Z"
    }
   },
   "outputs": [],
   "source": [
    "def plotData(x,y,c,style0,style1,title=''):\n",
    "    plt.scatter(x[c==0],y[c==0],**style0)\n",
    "    plt.scatter(x[c==1],y[c==1],**style1)\n",
    "    plt.grid(True)\n",
    "    plt.axis([x.min()-0.2, x.max()+0.2, y.min()-0.2, y.max()+0.2])\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting\n",
    "\n",
    "$\\DeclareMathOperator*{\\argmin}{arg\\,min}$\n",
    "\n",
    "El algoritmo de Gradient Boosting persigue construir un clasificador *ensemble* mediante un modelo aditivo, es decir, como suma de clasificadores débiles (*weak classifiers*). La idea general es obtener un clasificador $F(x)$ de la forma\n",
    "\n",
    "$$F(x)=\\sum_{i=1}^M h_m(x),$$\n",
    "\n",
    "de manera que realizamos una construcción iterativa en M pasos:\n",
    "\n",
    "$$F_m(x)=F_{m-1}(x) + \\gamma_mh_m(x), \\quad m=1,\\dots,M.$$\n",
    "\n",
    "Los multiplicadores $\\gamma_m$ son constantes que marcan el tamaño del paso y ponderan el peso de cada clasificador débil. El objetivo es optimizar los valores de $\\gamma_m$ y $h_m$ para minimizar la pérdida entre las predicciones y los valores reales en el conjunto de entrenamiento, utilizando un esquema de gradiente descendente. De esta forma, definimos nuestro clasificador inicial como aquella constante que minimiza la función de pérdida.\n",
    "\n",
    "Pasamos ahora a describir el algoritmo de Gradient Boosting:\n",
    "\n",
    "**Entrada**: \n",
    "\n",
    "- Conjunto de entrenamiento $\\{(x_n, y_n)\\}_{n=1,\\dots,N}$.\n",
    "- Función de pérdida puntual diferenciable $L(y,F(x))$.\n",
    "- Número de número de iteraciones $M$.\n",
    "\n",
    "**Procedimiento**:\n",
    "\n",
    "1. Se inicializa el modelo con un clasificador constante que minimice la pérdida esperada:\n",
    "$$\n",
    "F_0 (x) = \\argmin_{\\gamma \\in \\mathbb R} \\sum_{n=1}^N L(y_n, \\gamma).\n",
    "$$\n",
    "2. Para $m = 1,\\dots,M$:\n",
    "    1. Se calculan los *pseudo-residuos*:\n",
    "    $$\n",
    "        r_{nm} = - \\left[ \\frac{\\partial L(y_n, F(x_n))}{\\partial F(x_n)} \\right]_{F(x) = F_{m-1}(x)} \\quad n = 1,\\dots,N.\n",
    "    $$\n",
    "    \n",
    "    2. Se ajusta un modelo base $h_m(x)$ a los pseudo-residuos, es decir, se entrena $h_m$ sobre el conjunto $\\{x_n, r_{nm}\\}_{n=1,\\dots,N}$.\n",
    "    3. Se estima el multiplicador $\\gamma_m$ que minimiza el error en entrenamiento, utilizando si es necesario un único paso del método de Newton-Raphson:\n",
    "    $$\n",
    "    \\gamma_m = \\argmin_\\gamma \\sum_{n=1}^N L(y_n, F_{m-1}(x_n) + \\gamma h_m(x_n)).\n",
    "    $$\n",
    "    4. Se actualiza el modelo:\n",
    "    $$\n",
    "    F_m(x) =F_{m-1}(x) + \\gamma_m h_m(x).\n",
    "    $$\n",
    "    \n",
    "3. Devolvemos $F_M(x)$ como modelo final en el caso de regresión, o alguna transformación de la misma para clasificación, que transforme valores continuos en etiquetas de clase teniendo en cuenta cuál es la función de pérdida.\n",
    "\n",
    "Aunque el algoritmo descrito arriba representa el procedimiento estándar de construcción de estimadores, podemos añadir un par de técnicas de regularización para intentar prevenir el *overfitting*:\n",
    "\n",
    "1. **Learning rate.** Ponderamos la contribución de cada clasificador débil por un valor $0 < \\nu \\leq 1$, de forma que\n",
    "$$F_{m}(x)=F_{m-1}(x) + \\nu\\gamma_mh_m(x)$$\n",
    "\n",
    "2. **Stochastic Gradient Boosting.** Se trata de una modificación propuesta por J. Friedman ([paper](https://statweb.stanford.edu/~jhf/ftp/stobst.pdf)) en la que en cada etapa se utiliza una fracción de los datos para calcular los residuos, entrenar el clasificador débil y calcular los multiplicadores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error cuadrático\n",
    "\n",
    "Para el caso de regresión utilizamos como función de pérdida el error cuadrático entre predicciones y valores reales (convenientemente dividido entre 2 para simplificar los cálculos):\n",
    "\n",
    "$$\n",
    "L(y, F(x)) = \\frac{1}{2}(y - F(x))^2.\n",
    "$$\n",
    "\n",
    "Veamos ahora con detalle cuáles son los elementos que modelan el algoritmo en este caso.\n",
    "\n",
    "1. **Estimador inicial**. El valor que minimiza la pérdida cuadrática coincide con la media de las respuestas de los datos de entrenamiento:\n",
    "$$\n",
    "F_0(x) = \\argmin_\\gamma \\sum_{n=1}^N L(y_n, \\gamma) = \\argmin_\\gamma \\sum_{n=1}^N (y_n - \\gamma)^2\n",
    "$$\n",
    "$$\n",
    "\\dfrac{\\partial \\sum_{n=1}^N L(y_n, \\gamma)}{\\partial \\gamma} = -\\sum_{n=1}^N(y_n - \\gamma) = 0 \\implies F_0(x) = \\frac{1}{N}\\sum_{n=1}^N y_n = \\bar{y}.\n",
    "$$\n",
    "\n",
    "2. **Pseudo-residuos**. Como la función de pérdida es derivable, podemos calcular explícitamente su derivada parcial respecto de la segunda variable:\n",
    "$$\n",
    "r_{nm} = - \\left[ \\frac{\\partial L(y_n, F(x_n))}{\\partial F(x_n)} \\right]_{F(x) = F_{m-1}(x)} = -\\left[ \\frac{\\partial}{\\partial F(x_n)}\\frac{1}{2}(y_n - F(x_n)^2 \\right]_{F(x) = F_{m-1}(x)} = y_n - F_{m-1}(x_n).$$\n",
    "\n",
    "3. **Multiplicador**. Queremos minimizar en $\\gamma$ la siguiente función:\n",
    "$$\n",
    "f_m(\\gamma) = \\sum_{n=1}^N \\frac{1}{2}(y_n - F_{m-1}(x_n) - \\gamma h_m(x_n))^2\n",
    "$$\n",
    "Para ello, pretendemos calcular su derivada e igualarla a $0$. En primer lugar, se tiene:\n",
    "$$\n",
    "f_m'(\\gamma) = \\sum_{n=1}^N -h_m(x_n)(y_n - F_{m-1}(x_n) - \\gamma h_m(x_n)) \n",
    "$$\n",
    "Ahora, como $h_m$ se ha entrenado para que\n",
    "$$\n",
    "h_m(x_n) \\approx r_{nm} = y_n- F_{m-1}(x_n),\n",
    "$$\n",
    "podemos aproximar:\n",
    "$$\n",
    "f_m'(\\gamma) = \\sum_{n=1}^N - (y_n- F_{m-1}(x_n))(y_n- F_{m-1}(x_n) - \\gamma (y_n- F_{m-1}(x_n))) = (\\gamma - 1) \\sum_{n=1}^N (y_n- F_{m-1}(x_n))^2.\n",
    "$$\n",
    "Por tanto, concluimos que:\n",
    "$$\n",
    "f_m'(\\gamma)= 0 \\implies \\gamma_m^* = 1.$$\n",
    "\n",
    "Teniendo todo esto en cuenta, creamos una clase que represente estos elementos para la pérdida cuadrática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T16:24:21.202354Z",
     "start_time": "2020-11-16T16:24:21.176557Z"
    }
   },
   "outputs": [],
   "source": [
    "class SquaredErrorLoss:\n",
    "    \"\"\" \n",
    "    Define elementos para la función de pérdida cuadrática.\n",
    "    \"\"\"\n",
    "    \n",
    "    def F0(_, X, y):\n",
    "        \"\"\" Calcula el valor constate que minimiza la pérdida con la salida 'y'. \n",
    "            Para la pérdida cuadrática este valor coincide con la media de los \n",
    "            valores de 'y'. \"\"\"\n",
    "        \n",
    "        return np.mean(y)\n",
    "\n",
    "    def residuos(_, y, F):\n",
    "        \"\"\" Calcula los pseudo-residuos para un objetivo 'y' y \n",
    "            una salida del modelo 'F'. \"\"\"\n",
    "\n",
    "        return y - F\n",
    "\n",
    "    def paso_newton(_, X, y, residuos, hm):\n",
    "        \"\"\" Recibe el conjunto de entrenamiento ('X'), el valor a predecir ('y'), \n",
    "            los pseudo-residuos ('residuos')  sobre los que se entrena el nuevo \n",
    "            regresor, y el regresor ('hm'). Calcula el multiplicador asociado \n",
    "            al paso m. \"\"\"\n",
    "        \n",
    "        return 1.0\n",
    "    \n",
    "    def __call__(self, y, F):\n",
    "        \"\"\" Devuelve el valor puntual de la función de pérdida para un \n",
    "            objetivo 'y' y una salida del modelo F. \"\"\"\n",
    "        \n",
    "        return np.linalg.norm(y - F) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error logístico\n",
    "\n",
    "Hacemos el mismo análisis para el caso de clasificación, utilizando como función de pérdida el error logístico:\n",
    "\n",
    "$$\n",
    "L(y, F(x)) = \\log(1 + e^{-2yF(x)}), \\quad y \\in \\{-1,1\\}.\n",
    "$$\n",
    "\n",
    "En este caso la estrategia será un poco distinta, pues aprovecharemos que los estimadores débiles que usamos son árboles de decisión de profundidad $J$, es decir, de la forma \n",
    "\n",
    "$$h_m(x)=\\sum_{j=1}^{J} b_{jm}\\mathcal{I}(x \\in R_{jm}),$$\n",
    "\n",
    "donde $\\mathcal I(\\cdot)$ es la función indicadora y $\\{R_{jm}\\}_{j=1,\\dots,J}$ son las regiones en las que se divide el espacio de entrada, representadas por las hojas terminales del árbol en el paso $m$-ésimo. En este caso, podemos mejorar la calidad del ajuste calculando un multiplicador diferente en cada nodo, es decir, construyendo los estimadores como\n",
    "\n",
    "$$F_m(x) = F_{m-1}(x) + \\sum_{j=1}^{J} \\gamma_{jm}\\mathcal{I}(x \\in R_{jm}).$$\n",
    "\n",
    "Notamos que, esto es equivalente a \"descartar\" los valores $\\{b_{jm}\\}$ del árbol de decisión y considerar que los multiplicadores son $\\gamma_{jm}=\\rho_m b_{jm}$, donde $\\rho_m$ serían los multiplicadores a nivel de árbol que usaríamos siguiendo el algoritmo general. Por último, teniendo en cuenta que las regiones $\\{R_{jm}\\}$ son disjuntas, concluimos que\n",
    "\n",
    "$$\\gamma_{jm}= \\argmin_\\gamma \\sum_{x_n \\in R_{jm}} L(y_n, F_{m-1}(x_n)+\\gamma). $$\n",
    "\n",
    "Veamos entonces cómo serían los pasos del algoritmo:\n",
    "\n",
    "1. **Estimador inicial**. En este caso, <a href=\"#Análisis-matemático-de-la-pérdida-logarítmica\">se puede demostrar</a> que el valor del estimador constante inicial es:\n",
    "$$\n",
    "F_0(x)=\\argmin_\\gamma \\sum_{n=1}^N L(y_n, \\gamma) = \\argmin_\\gamma \\sum_{n=1}^N \\log(1 + e^{-2y_nF(x_n)}) = \\frac{1}{2}\\log \\left(\\frac{1+\\bar{y}}{1-\\bar y}\\right).\n",
    "$$\n",
    "\n",
    "2. **Pseudo-residuos**. Se tiene que:\n",
    "$$\n",
    "r_{nm} = - \\left[ \\frac{\\partial L(y_n, F(x_n))}{\\partial F(x_n)} \\right]_{F(x) = F_{m-1}(x)} = -\\left[ \\frac{\\partial \\log(1 + e^{-2y_nF(x_n)})}{\\partial F(x_n)} \\right]_{F(x) = F_{m-1}(x)} = \\frac{2y_n e^{-2y_nF_{m-1}(x_n)}}{1 + e^{-2y_nF_{m-1}(x_n)}} = \\frac{2y_n}{1 + e^{2y_nF_{m-1}(x_n)}}, \\quad n = 1,\\dots, N.\n",
    "$$\n",
    "\n",
    "3. **Multiplicador**. Queremos minimizar en $\\gamma$ las siguientes funciones:\n",
    "$$\n",
    "f_j(\\gamma) = \\sum_{x_n \\in R_{jm}}L(y_n, F_{m-1}(x_n) + \\gamma) = \\sum_{x_n \\in R_{jm}}\\log\\left(1 + e^{-2y_n(F_{m-1}(x_n) + \\gamma)}\\right), \\quad j = 1,\\dots, J.$$\n",
    "Como este problema de optimización es complicado, aproximamos el valor del mínimo estimando la raíz de su derivada mediante un único paso del método de Newton-Rhapson, con condición inicial $\\gamma=0$:\n",
    "$$\n",
    "f_{jm}'(\\gamma) = \\sum_{x_n \\in R_{jm}} \\frac{-2y_n  e^{-2y_n(F_{m-1}(x_n)+\\gamma)}}{1 + e^{-2y_n(F_{m-1}(x_n)+\\gamma)}} = \\sum_{x_n \\in R_{jm}} \\frac{-2y_n}{1 + e^{2y_n(F_{m-1}(x_n)+\\gamma)}},\n",
    "$$\n",
    "$$\n",
    "f_{jm}''(\\gamma) = \\sum_{x_n \\in R_{jm}} \\frac{4y_n^2e^{2y_n(F_{m-1}(x_n)+\\gamma)}}{\\left(1 + e^{2y_n(F_{m-1}(x_n)+\\gamma)}\\right)^2}.\n",
    "$$\n",
    "Por tanto, se tiene que:\n",
    "$$\n",
    "\\gamma_{jm}^{*} = -\\frac{f_{jm}'(\\gamma = 0)}{f_{jm}''(\\gamma = 0)} = \\dfrac{\\displaystyle \\sum_{x_n \\in R_{jm}}r_{nm}}{\\displaystyle \\sum_{x_n \\in R_{jm}} \\dfrac{2y_ne^{2y_nF_{m-1}(x_n)}2y_n}{(1 + e^{2y_nF_{m-1}(x_n)})(1+e^{2y_nF_{m-1}(x_n)})}}.\n",
    "$$\n",
    "Ahora, de la fórmula de $r_{nm}$ deducimos que $e^{2y_nF_{m-1}(x_n)}=\\frac{-2y_n-r_{nm}}{r_{nm}}$, y teniendo en cuenta que $y_n\\in \\{-1, 1\\}$, llegamos a que\n",
    "$$\n",
    "\\gamma_{jm}^{*} =\\dfrac{\\displaystyle \\sum_{x_n \\in R_{jm}} r_{nm}}{\\displaystyle \\sum_{x_n \\in R_{jm}}|r_{nm}|(2-|r_{nm}|)}.\n",
    "$$\n",
    "\n",
    "4. **Transformación de la salida a etiquetas.** Como esta pérdida la usamos para resolver un problema de clasificación, debemos transformar la salida de nuestro regresor $F_M$ en etiquetas de clase. Para ello utilizamos la función *sigmoide*, adaptada convenientemente para el caso en que las etiquetas son $\\pm 1$:\n",
    "$$\n",
    "\\hat \\sigma(x)=\\frac{1}{1 + e^{-2x}}\n",
    "$$\n",
    "De nuevo, <a href=\"#Análisis-matemático-de-la-pérdida-logarítmica\">se puede demostrar</a> que la transformación \n",
    "$$\n",
    "F_M(x) \\mapsto \\hat \\sigma(F_M(x))\n",
    "$$\n",
    "transforma la salida en una probabilidad entre $0$ y $1$, de forma que nuestro modelo final queda como\n",
    "$$\n",
    "P(y=1\\mid x)=\\hat \\sigma(F_M(x)).\n",
    "$$\n",
    "De esta forma, para cada nuevo ejemplo $x$ daremos como predicción la clase $\\hat y(x)\\in\\{-1, 1\\}$ que verifique \n",
    "$$P(y=\\hat y\\mid x)\\ge P(y\\neq \\hat y\\mid x).$$ Dada la simetría entre las etiquetas, y en vista de que la función sigmoide es creciente y toma el valor $0.5$ en $x=0$, tenemos finalmente que esto equivale a\n",
    "$$\n",
    "\\hat y(x)=\\operatorname{signo}(F_M(x)).\n",
    "$$\n",
    "\n",
    "*Nota*: no aplicamos esta estrategia en el caso de la pérdida cuadrática porque no proporciona un nuevo algoritmo; el clasificador final seguiría siendo el mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:12:34.867579Z",
     "start_time": "2020-11-17T11:12:34.852195Z"
    }
   },
   "outputs": [],
   "source": [
    "class LogLoss:\n",
    "    \"\"\" \n",
    "    Define elementos para la función de pérdida logarítmica.\n",
    "    \"\"\"\n",
    "    \n",
    "    def F0(_, X, y):\n",
    "        \"\"\" Calcula el valor constate que minimiza la pérdida con la salida 'y'. \"\"\"\n",
    "        \n",
    "        ybar = np.mean(y)\n",
    "        \n",
    "        return 0.5 * np.log((1.0 + ybar) / (1.0 - ybar))\n",
    "\n",
    "    def residuos(_, y, F):\n",
    "        \"\"\" Calcula los pseudo-residuos para un objetivo 'y' y \n",
    "            una salida del modelo 'F'. \"\"\"\n",
    "\n",
    "        return 2.0 * y / (1 + np.exp(2.0 * y * F))\n",
    "\n",
    "    def paso_newton(_, X, y, residuos, hm):\n",
    "        \"\"\" Recibe el conjunto de entrenamiento ('X'), el valor a predecir ('y'), \n",
    "            los pseudo-residuos ('residuos')  sobre los que se entrena el nuevo \n",
    "            regresor, y el regresor ('hm'). Calcula el multiplicador asociado \n",
    "            al paso m. \"\"\"\n",
    "        \n",
    "        residuos_abs = np.abs(residuos)\n",
    "        X_leaves = hm.apply(X)\n",
    "        \n",
    "        return np.sum(residuos) / np.sum(residuos_abs * (2.0 - residuos_abs))\n",
    "    \n",
    "    def raw_preds_to_proba(self, y):\n",
    "        \"\"\" Transforma las predicciones 'y' del regresor final F_M en\n",
    "            probabilidades de clase {-1, 1}, aplicando una sigmoide. \"\"\"\n",
    "        \n",
    "        proba = np.ones((y.shape[0], 2), dtype = np.float64)\n",
    "        proba[:, 1] = 1.0 / (1.0 + np.exp(-2.0 * y))\n",
    "        proba[:, 0] -= proba[:, 1]\n",
    "        \n",
    "        return proba\n",
    "        \n",
    "    def raw_preds_to_labels(self, y):\n",
    "        \"\"\" Transforma las predicciones 'y' del regresor final F_M en\n",
    "            etiquetas de clase {-1, 1}, tomando el signo. \"\"\"\n",
    "        \n",
    "        sgn = lambda x: 1 if x >= 0 else -1\n",
    "        \n",
    "        return sgn(y)\n",
    "    \n",
    "    def __call__(self, y, F):\n",
    "        \"\"\" Devuelve el valor puntual de la función de pérdida para un \n",
    "            objetivo 'y' y una salida del modelo F. \"\"\"\n",
    "        \n",
    "        return np.log(1 + np.exp(-2.0 * y * F))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación de Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:54:09.261659Z",
     "start_time": "2020-11-17T11:54:09.238013Z"
    }
   },
   "outputs": [],
   "source": [
    "class BaseGB():\n",
    "    def __init__(self, n_estimators, learning_rate, loss, \n",
    "                 max_depth, subsample, random_state):\n",
    "        self.n_estimators_   = n_estimators\n",
    "        self.random_state   = random_state\n",
    "        self.max_depth      = max_depth\n",
    "        self.learning_rate  = learning_rate\n",
    "        self.subsample      = subsample\n",
    "        self.loss_           = loss\n",
    "        self.estimators_    = []\n",
    "        self.multipliers   = []\n",
    "        \n",
    "    def _update_F(self, mult, X, tree):\n",
    "        raise NotImplementedError('_update_F method not implemented')\n",
    "    \n",
    "    def fit(self, X, y): \n",
    "        n = X.shape[0]\n",
    "        self.n_features_ = X.shape[1]\n",
    "        \n",
    "        if self.subsample < 1.0:\n",
    "            np.random.seed(self.random_state)\n",
    "        \n",
    "        # Get initial constant estimator \n",
    "        self.F0 = self.loss_.F0(X, y)\n",
    "        \n",
    "        # Set initial mask\n",
    "        sample_mask = np.arange(n)\n",
    "        n_inbag = int(self.subsample * n)\n",
    "        if n_inbag == 0:\n",
    "            raise ValueError(f\"Empty training set after selecting a fraction of {self.subsample} out of {n}\")\n",
    "        \n",
    "        # Loop trough iterations\n",
    "        F = np.full(n, self.F0)\n",
    "        for i in range(self.n_estimators_):\n",
    "            # Set base tree learner with desired depth\n",
    "            tree = DecisionTreeRegressor(criterion = \"mse\",\n",
    "                                         max_depth = self.max_depth, \n",
    "                                         random_state = self.random_state)\n",
    "            \n",
    "            # Select training subset for this iteration\n",
    "            if self.subsample < 1.0:\n",
    "                sample_mask = np.random.choice(n, size = n_inbag, replace = False)\n",
    "            \n",
    "            # Get pseudo-residuals from loss function\n",
    "            r = self.loss_.residuos(y[sample_mask], F[sample_mask])\n",
    "            \n",
    "            # Fit base learner to pseudo-residuals\n",
    "            tree.fit(X[sample_mask, :], r)\n",
    "            \n",
    "            # Compute multipliers\n",
    "            mult = self.loss_.paso_newton(X[sample_mask], y[sample_mask], r, tree)\n",
    "            \n",
    "            # Save multipliers and predictions for this step\n",
    "            self.multipliers.append(mult)\n",
    "            self.estimators_.append(tree)\n",
    "            \n",
    "            # Update F\n",
    "            F += self.learning_rate * self._update_F(mult, X, tree)\n",
    "            \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        raise NotImplementedError('predict method not implemented')\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        raise NotImplementedError('score method not implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:54:09.407871Z",
     "start_time": "2020-11-17T11:54:09.396381Z"
    }
   },
   "outputs": [],
   "source": [
    "class RegressorGB(BaseGB):\n",
    "    def __init__(self, n_estimators = 100, loss = SquaredErrorLoss(), \n",
    "                 learning_rate = 0.1, max_depth = 3, subsample = 1.0, \n",
    "                 random_state = 2020):\n",
    "        super().__init__(n_estimators, learning_rate, loss, \n",
    "                         max_depth, subsample, random_state)\n",
    "        \n",
    "    def _update_F(self, mult, X, tree):\n",
    "        pred = tree.predict(X)\n",
    "        \n",
    "        return mult * pred\n",
    "        \n",
    "    def predict(self, X):\n",
    "        y = np.full(X.shape[0], self.F0)\n",
    "        for i in range(self.n_estimators_):\n",
    "            y += self.learning_rate * self.multipliers[i] \\\n",
    "                   * self.estimators_[i].predict(X)\n",
    "                \n",
    "        return y\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return SquaredErrorLoss()(y, self.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:59:42.713013Z",
     "start_time": "2020-11-17T11:59:42.687276Z"
    }
   },
   "outputs": [],
   "source": [
    "class ClassifierGB(BaseGB):\n",
    "    \n",
    "    def __init__(self, n_estimators = 100, loss = LogLoss(), \n",
    "                 learning_rate = 0.1, max_depth = 3, subsample = 1.0, \n",
    "                 random_state = 2020):\n",
    "        super().__init__(n_estimators, learning_rate, loss, \n",
    "                         max_depth, subsample, random_state)\n",
    "        \n",
    "    def _update_F(self, mult, X, tree):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Check class labels \n",
    "        classes = np.unique(y)\n",
    "        if (classes != [-1, 1]).any():\n",
    "            raise ValueError('Binary classes must be [-1, 1]')\n",
    "        self.classes_ = classes\n",
    "        \n",
    "        super().fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        y = np.full(X.shape[0], self.F0)\n",
    "        for i in range(self.n_estimators_):\n",
    "            y += self.learning_rate * self.multipliers_[i] #*...\n",
    "                \n",
    "        return y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        raw_predictions = self.decision_function(X)\n",
    "        \n",
    "        return self.loss_.raw_preds_to_labels(raw_predictions)\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        raw_predictions = self.decision_function(X)\n",
    "        \n",
    "        return self.loss_.raw_preds_to_proba(raw_predictions)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\" Calcula el accuracy de la predicción. \"\"\"\n",
    "        \n",
    "        return np.mean(self.predict(X) == y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:56:07.412232Z",
     "start_time": "2020-11-17T11:56:07.390377Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(11)\n",
    "n = 50\n",
    "model = 'sine'\n",
    "ymargin = 0\n",
    "noise = 0.2\n",
    "\n",
    "# We are using the same points for regresion and clawsification. \n",
    "# For regresion we use (x, y) and for classification ((x,y), c).\n",
    "Xtrain_reg, Ytrain_reg, Ytrain_class, = createDataSet(n, model, ymargin, noise)\n",
    "Xtest_reg, Ytest_reg, Ytest_class = createDataSet(5 * n, model, ymargin, noise)\n",
    "\n",
    "Xtrain_class = np.concatenate((Xtrain_reg, Ytrain_reg), axis = 1)\n",
    "Xtest_class = np.concatenate((Xtest_reg, Ytest_reg), axis = 1)\n",
    "Ytrain_reg = Ytrain_reg.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:56:07.999878Z",
     "start_time": "2020-11-17T11:56:07.815839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotData(Xtrain_reg, Ytrain_reg, Ytrain_class, {'c':'#FF0000'},{'c':'#0000FF'})\n",
    "Ytrain_class[Ytrain_class == 0] = -1\n",
    "Ytest_class[Ytest_class == 0] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:56:11.104154Z",
     "start_time": "2020-11-17T11:56:10.992472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 0.9181678236547842\n",
      "Test MSE: 46632.05117535146\n"
     ]
    }
   ],
   "source": [
    "gb = RegressorGB()\n",
    "gb.fit(Xtrain_reg, Ytrain_reg)\n",
    "\n",
    "print(f\"Training MSE: {gb.score(Xtrain_reg, Ytrain_reg)}\")\n",
    "print(f\"Test MSE: {gb.score(Xtest_reg, Ytest_reg)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:56:11.289871Z",
     "start_time": "2020-11-17T11:56:11.249285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE sklearn: 0.9181678236547842\n",
      "Test MSE sklearn: 46632.05117535146\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gb_sk = GradientBoostingRegressor(criterion=\"mse\", random_state=2020)\n",
    "gb_sk.fit(Xtrain_reg, Ytrain_reg)\n",
    "\n",
    "print(f\"Training MSE sklearn: {SquaredErrorLoss()(Ytrain_reg, gb_sk.predict(Xtrain_reg))}\")\n",
    "print(f\"Test MSE sklearn: {SquaredErrorLoss()(Ytest_reg, gb_sk.predict(Xtest_reg))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:59:46.781203Z",
     "start_time": "2020-11-17T11:59:46.743172Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-410-7be8139065b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgbc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifierGB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrain_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training accuracy: {gbc.score(Xtrain_class, Ytrain_class)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test accuracy: {gbc.score(Xtest_class, Ytest_class)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-409-2f284d9de408>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-391-77f350570df0>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;31m# Update F\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mF\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_F\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "gbc = ClassifierGB()\n",
    "gbc.fit(Xtrain_class, Ytrain_class)\n",
    "\n",
    "print(f\"Training accuracy: {gbc.score(Xtrain_class, Ytrain_class)}\")\n",
    "print(f\"Test accuracy: {gbc.score(Xtest_class, Ytest_class)}\")\n",
    "\n",
    "plotModel(Xtest_reg, Ytest_reg, Ytest_class, gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-17T11:56:27.847168Z",
     "start_time": "2020-11-17T11:56:27.576125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.896\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAABdq0lEQVR4nO2deXhcZb34P+9kMtnTZmuaJulCN5GdloKFosBlKVQrVbAWFRVBKCheb68/oFihslTtRfDKYhXvBRUrakux7CJIEVlaLkgLtHTN0iZtk7TNMpPJzLy/PyaTzHLOzJmZc+bMpO/nefIkc+bMe74zc/J+3/e7CiklCoVCoVDo4bBbAIVCoVBkN0pRKBQKhSIuSlEoFAqFIi5KUSgUCoUiLkpRKBQKhSIuSlEoFAqFIi62KgohxK+FEPuFEJt1nv+UEOKwEOKdwZ9lmZZRoVAojnacNl//f4GfA4/GOWeDlHJeZsRRKBQKRTS27iiklK8AnXbKoFAoFIr42L2jMMInhBDvAnuBJVLKLVonCSGuAa4BKCgonFFX32C6IA4hCUiR9Ov8gQBCgJSQ5wjqZgnkOQR5QuC3MDs+TwzLK2UAIXLTLWWV7KHP3h+QJP/NGifVeycbyGXZIbfldwgJGfqf3bn9o4NSyhqt57JdUbwNTJBS9gghLgaeAKZqnSilXAWsAqieeKz85C3/a7ownxp1kJcPVyf9ulf//jYTq0vYfbCXsz55KgAHe7xcMKOe86ZU8+L2gxQ5zb8Z3L4A500Zlrd580Yaj59p+nUygVWyhz77dW80U13qMn38EKneO9lALssOuS3/WWUHkOOPz8i1rvnEpD16z2X18lJKeURK2TP499NAvhAiN79xhUKhyFGyWlEIIcYKEbSdCCFmEZS3w16pFAqF4ujCVtOTEOL3wKeAaiFEC/ADIB9ASvkQ8HngOiGED3ADC6Uqd6tQKBQZxVZFIaX8YoLnf04wfFahUCgUNpHVpieFQqFQ2I9SFAqFQqGIi1IUCoVCoYhLtudRjBj2fTCRPRtOYcdvSimp9DL14l0ww7rrvfFcCWseHM139jsZWy+58WYPJ02z7noKhWLkonYUGaB75xQ+/OtsfL1lgKC3s4D3/jCVjc+XWHK9N54r4Tcrquhqz0dKwb4WB7ctKeJQlyWXUygUIxylKDJA5ztnEPBFbt78A3msX1VpyfXWPlSB1xP51Xrcgv1tufN1r1/j5PzTSjlhXBnnn1aqlJxCYSO5M3PkML7eUs3jXfutsfx1tudpHh/wWnI501m/xsltS4rY1+IY2hHtbXGwfo2ylCoUdqAURQZwlvRoHq8Y47PkepW1fs3j+daVMjKV++4uxOOOLOImA8HjCoUi8yhFkQEqT34dhzNSKeTl+5l3jTUV1i+9tgtXYSDiWGGRZMzYgM4rsou2Vu1Kn3rHRxI7X6/iT987mUe+MYs/fe9kdr5eZbdICoWKesoEZcdsp7qsgG0bTsHXOxz1NPMCF1Bk+vVOv7AXgDUPjuZQWNTT6ArTL2UJY+sl+1pilcLY+pFdvWXn61W89ugk/N6g6bC3s4DXHp0EwDFnqBJnCvtQiiJD1B27m/6aLRFlxqHesuudfmEvJ57XHVVm3LLLmcqNN3u4bUlRhPlJOILHRzJvr2kcUhIh/N483l7TqBSFwlaUolBkJQWFEo87+PfoCsm4hgAnzLHGp5MuO1+v4u01jfR2uiip9HLqguaUJvbeTm0nkt7xbMasz0SRHShFocgqQhFP4bsJTxZvJMw0F5VUeuntLNA8nksoE1p28cZzJax9qILO9jwqa/1cem3XkHnaKMqZrcgqtCKesjkHJJ65KFlOXdBMnisyYi3P5efUBc1pyZhpzPxMFOkRSr7tbHOCFHS2OfnNiireeC65ZF+1o1BkFXqRTdmaA2KmuSi02s51k02iz0SZpTKHVvKt1+Ng7UMVSe0qlKJQGKJ8zePU3r2c/NYWBuobaL95GUcWXG76dfQinrI1B8Rsc9ExZ3Tk/KQZ7zNRZqnMopd8q3dcj+zczyuyivI1j1O/5Nu4WpoRUuJqaaZ+ybcpX/N4TKmNdLOnb7zZQ2FRZBhsNueAxDMXhedEdLUWHzU5EfE+E2WWyix6ybd6x/VQikKRkNq7l+NwuyOOOdxu/nbruzGlNm5bUpSWspi3wMdtK93UNQQQQlLXEOC2le6szQE55owOZn9lFyWV/YCkpLKf2V/ZBcBrj04aXFkLAj7Ba49OOiqUhd5ncswZHSMqsisX0Eq+dRUGuPTa5IqnKdOTIiH5rS2ax5d1/QceYh3P991dyLwF2mVLjDBvgS/m9dmcA6JlLvrT904+qnMi9ExoIyWyK1cI+SHSjXpSikKRkIH6BlwtsZE3zYzXPP9oKLWRCLVy1ubUBc0RPgrIzciuXOL0C3uTVgzRKNOTIiHtNy8jUBRZaiRQVMS4Cu2bb6SX2jCC3gr5aF85xzNLKbIXtaNQJCQU3RQd9fQt8rhtiYzIeygskiO+1IYR1MpZn5EQ2XW0oRSFwhBHFlweEw47Dx/g5r67C2lrFUPFB+ct8GUsnDZV1q9xct/dhexrLaOy1s/4f/NQ/anDpo0fnRPhcMqcWTlH5zl84p6X7RYp6zjackGUotDgaLsJ0kHL8RwKpw1FSoXCaYGsUBbRZUI625wc/sNUygrNncjDV84Vo/o4pjT77yGtPIeejgJ2flCVU/8D4f/DJ937Mjs3myf/0ZgLonwUUYRuglBYY+gmOBrCGs1CL5y29u7lNkkUiVaZEP+AiuUH7fIbSHLqs4n+HzY7NPlozAWxVVEIIX4thNgvhNAMfhRBfiaE2C6E+JcQ4lSrZToabwKz0Qun1TueafSiso72iCQYGdFaVv8Pj4TPKFnsNj39L/Bz4FGd5+cCUwd/TgceHPxtGUfjTWA2euG0A/UNNkgTi16ZkKM9IgnSz3PIBrOt1f/DR2MuiK07CinlK0C8fqDzgUdlkNeB0UKIOitlMjus8dW/v637uMjp4MXtB1MaN5vRC6dtv3mZTRJFolUmJC//6I5ICpUbCU6mUeHNAkOfTbaYba0OTR4pVX6TQUhpb8y7EGIisF5KebzGc+uBFVLKVwcfvwj8PynlRo1zrwGuAaisHjPjvx78dUry9Pc66ekoiPxfEVBa1U91uYduf3KbsJ6ePlzOYX3s9QXT6QuLixhd4iIweB2HBTlqAQnlhcPyet29uIqSKy+cKnldnTjb9iG8XqTLhW9sHf6KypTHM0P2Q12wv83BgBfyBi0Tfj8488FV5qGoLLn6N8lQludL+t7JFJr3fBgNjd0ccrsoKInfOKqrtZiAL/ZGdjglFfV9ZohqiOj309DQQ0trKaVV/QnfQzLX6DvkIuATOJyS4tFe08YOpzTPx6GB5Ar4pcrVX/j0JinlTK3nsvPOTQEp5SpgFUD1xGPly4erE7xCn50faG+fP+U/SDLjhnYPE6sjJ7jdB3v52IzjmX96I+5BxVHkNH9z5/YFOC6iFepGGo/XvA+ynnRl12qIVFgkuWzJfuZc7GbdG81UB6wzL35qVHL3TiYJ7iRiTSkhVq58mf93y5yE4b2PfGcWoLXikVz5qzfTFzQJwv+H77n3ZdZ90BCU3bwIaCgN+9tXbO7Yg3xq1EFe7bb/vsl2RdEKhHugGgaPWYqZCUHRSkJhD3oNkdavqmTOxZbfUlmNEdu9kTpV2WC7j/aRzPnGDirqcyM0OZvJdkXxJHCDEGI1QSf2YSnlPptlSordB/VrrIR2E6G/zdxVuH0BOttaeWbL3wmZFzuad1K1fbcp4wshhn4yQUfTTqp2GbMB93v66ek+QveRw/T19iKlZF+Li+BqN1zeWrrarzJFvmxw4qaK3gQfTSKFYnc2ul5+wxVn7cjI9c3mYI8XX5nkYI/9TnJbFYUQ4vfAp4BqIUQL8AMgH0BK+RDwNHAxsB3oA75mZFxfwJoPN9kv7WMzYtwuQwSkpGNfC62vPMGxx59E4JgZUFRshph07G3m+UfvZ+Nza/H5zLebjiSE4x5e/9vN+Is+nvI907qxhvf+MAn/QNgE9cgkuj0+6mceAJK/dzLJ1It38d4fpg7Jr0dRRX/c91B+/D5OuNzH1qcm4u4qoKiin+mX7Kb8+AO8+3JNzPHQZ2MWG//coBkW29fl4qDIzs8+HgEpKS92ccGM+oxc76k4z9mqKKSUX0zwvASuT3bc8uJ8Sz7c8kPupMfV2iW4fQF83n5+dMV57G8LbpAmT/sYT7z0etoytrW28JmvXozb3YfD4eCiM2dSVhxUQAf7A1QXpL9rkUiklCQbCCHaDiC274Z+LxS4kFMmIsfWGHrtQY+kutDY7sWVn095aTHlRYWUFRchhOBfH41i3ct1DPhD71/iEH8mEHibXy9dzBU3/5hZF38uqfcT4ra7G2MmWf9AHntemMzXvhlchady72SMGbBx0kHWr6qka7+T4jI//W4H/oHheyW/IMDnbzjMzETvYQbwzb1hB1xsfH4az/+xhoH+4HjurkK2/HEaJ0yqYOYF6VU1DeepQ9q7ooBfcMHpWfrZJ6Dcs3vIzxgqOxNeLgfQLKFjNtluespp4pmSzp9ex08Lhm/sKZMmIKVM25STX1CAzx+8UVb/6GYunFg79NzGvFpm+tsBcG54i8LH1iM6upBVFXgWzcM357S4Y6fymvDXFm14E+EdCB7o9yI/2oX7vNMNjREuezK4m/YE/5gK59RO5O5n5tLaVUF9RRe333AuP3z0C+ze08THako4b0pqTsPv7Nf+Nzq03zk0ZvPm3RGBBVrYGSo984LeiEl74/MlQ4ojL1+y8HsHUp7U16+qHFISIQb6HaxfVWmqoqgY46OrPT/meF5+7lUzDr9vIDYYY1+L4PvfKUICvoHhY7ctKQLcpiuLEakoHEJYEkXkEKlFJ617Y9hGO//0RoqcDl7a1cl9D/+OxlEuHlv7FFd+84agzT/NONnqMWP4wleu4re/epDfvPw282+/Yeg50e5j7dtnsWzlRJoPX894mriTW7ji4O8pWvU4/ppaAnPP0RzX8cxL5K16HOHpD451sCvha8LJ/9YPh5VESB7vAEWPP8vAVxYmfL1o91FYOznheeF4du2gaPyEocdfGt/Jly793dDjLe4Au/c0UT56NIUnfDLliXr0mCLNCWr0GN/QmGM9voTjW3HPpsqci91DTv6KjgFKZrkxknb1xnMlMU1yunQUadd+p6nvecF1h/jNiiq8nuExXYUBKmr8eLPoszVC6F6ZNvhYKxhjYCB2rjCjcZgWI1JRZBPr3mimutQV8Rjgghn1TD/ueGRActX130lbQYSz8Mpv8NtfPcjb77xLXsWYoeNdOzpZfNeJ9LmDZpI9TOQafgnAFZ7fk/fgbxGLvqA5puPB3w4piRDC0x/3NRG060yS7QcjZNRDdOw3dF4If9f+hOds2bEbgLPOOR9XYVHKk5beBLXgukNDY6a6yMgl3niuJOJz6Gxz8psVVZSUB+g9HOv/0OrbrKVojDbd0evmVlIeINc8FEVOR0SwSzLNwKxoHKYURYapLnVZ7tQsKNC21ba25Q8piRB9lLCUu7iC38O+OKYdvefivSaculrY26Z9PAXEumcQKx8IXr+uFrlkMXL+3JTGcjrT+zcwq91krrP2oYoIZQng9TjId/lxFQZiFGl032Y9RQMkpSxizs2N4LO46JWd0TvXbJSiSJJUVjx6ikEG5JBfQgakabuK3TuD4YCjyssjVtbeAe2oqqZQS9Paat2VuKO2Gto0olTivCYced2XyLvzvyN2JbKwAP91XyJg5PU+39B1HM+8hCN8rL1tcMudBHqPGDKDhSgdLDPSvi/ofA1fwRkhfIdgtN2k3jVGwm6js107aqq328FVPziY8P9GT9Gsfagi55VuOjslCJadiU4YHU6lt75xmFIUSdB7xJH0imf+6bEVK0OTxYa/vcB/XvtVbr7lFuZ/9XrTlMVf/rwagM+eeTIQtNUDuJzHaZ4/niakKx/35Rfh26Udc+67/CKKHlod4WdI9JoIPjYe5zWXxzrDPzYeDLxe5tXi2RXcvZTe97CmGcxx38P0fUy7j7cWZ888AYfDwaY3XuNnYwsoKS0z/FpIzvk8Sg5/79FO8xe3H7Q0Qz/dScoolbV+Ottip5TKWr8hRaqnaPSO5wrJ7pTC75OQMzvonHaz4tZCDnWF8oEG5wohQUJdg4p6ygoOHXCatuI5b0o137n7UXp7e7l16VIWL15Ma585O4rXN7wMwGXnnz2kJADqKnsocg3g9g47Xovp5Y7SO3F/fWHc6CPfnNNwg6GoJ73oKN+c0+gxGCUVD9HRldRxPapHj+KUk09k09vvsPn/3ub0OZ9M6vXJREnFi3oKjROuMMxi4/MlrP5x1VDUUWebk0fvrsLrD2hGHKWjqC69tkvTVxNtYtIjnqLJZVLZKWndW/MW+LjvbgYVRRhSUNcQ4IW3zHVgh6MURRL4BrSPp7riCc9D8Hq9QOLsWCP4BoKCVleMgsPDBtrKUg8/u/ZFlj82m5aOMhqqulm26DU+M+dEjKxBjEz0zg1vRew8xMEuih5ajXvw9WYgqyoQB2MnH1lVkdQ4nl07GJ0f/KfLhsTEVMNz47Hii6Waoal//Z8a/t/iyAq/6YbnpuurSVfRZCtm7pT0HNVWOLDDUYoiCZyxEZBA/BWP1rb/xPO6ATjUNVxhPS8vD0OztREGczG8A7EDXj7nIy6f85FJF4ql8LH1mmGwhY+tN2U3AeBZNE/TDOZZNC/psYYURIZKkSTC7FyKfa3a5rR9rSKlayUyYxn11WgxUoMCzNwp6Tm1rXBgh6MURRKMrvEZit4IoWeb/II/wHlT4MJPX8qm119jypQplJaWQr85TqiJk6fQefAA//poJ+fWZ7YXgFlmoXgkYwaLR+GkyWxtDTroGydOBLSzX62w+UYTPmmb6aeIN0klex0zopISkY6iMUqmfDYhzNwpaTm1rXJgh6MURRKUlAf48k0dhm8yPdvkU7+sYuYFTXzxq1fz/f/4FlJKtnd4TIt6OmnGLN5+45+8+d5WLj7ryxF+CqsxyyyUCDP8HR2HjtDW1kZxSSkN4ydqZr/etqSI/3vTyysv5lumPEJKwgwFET0JnjC7j38+XZryJPXGcyWcUOHiO5+egENAIBB5j+ZaVFImlF00ye6UQg3N9PwU4M74YkYpiiRJZsVj1DZpdgXWseOCdW0OezPvBDTTLGQ1R3qDzXQqKitxOBy6pcj/8KgLpLVlEsxSEtGT4D+fLuUTF/fw3mvFSa+gQ+PddQcgxVCTrWhyKSrJrhBcM3dK8xb4TM+8ToRSFBaSyDa5+Z23+dkTv+eYyZP5+BnncMy06aYojVBegNkYqfVkllkok4SCCnQdgjJWeWiVSbDLbBVCbxJ877ViVqxtMWU8LXIpKmmkhuBazYhUFAEpTQ8zhMhYeCNccnUHq39cExF1kl8Q4KKv7+PpX/2Uv/72Qfz+4X+y+sbxTD/uBEpKSikuKaWgsDBCcez8yMHbbzrp7YGSUjh1lo9jpkbK075vL88+uQaAGZNjczhSJZloJrPCYK2mclQZDoeD/e1t9PZ0M260oLXLWC5FtFLRM1tZUaBND7MnQSOvy7WopJEagms1I1JRlBU4OfcY8524LVt28fEkxj33WjhujIf7VhTStlcwdpzk6m/t5Y+/+zQfvPcuQgi+sWAubk8/z73xLq3NTbQ2Nxkau7cHNvwt+BNNfn4+9/zHNXzu4xNM809kIprJLIYqxiaiaQ8zTz2FNzdu4q1/vMqdvMpiVtDHcFdCQQCpUQwvOspEz2xltECbGY2rzJ4E9cZzOCQBSU5GJeVSCO6L2w8OFQW0mxGpKAqdDqZUFZo+7oEUxr3xarhkQffQ65577m2Wv/cuVZWVrL77e8yqDJbVyP/Bd/i/D3ewt9dLT6+bnr4++tzDkQx3P1DHoSOxX9foch83Lx5u+ieE4NwTpzLVGdxphE+agfoK3K0GJ9EoyjQc1BDcWRiemONQuOkDSp/ZgKOrm0BFGT1z5+CZcezQ88nKfmBX4sm5ZlIpp06q482NsHvHR/z40P046WApd9HEeMbTxMWs5xG+FqE8tKJM7IpvD8fsSTA0XjiuwmBARy4ph3ByJQQ3uiig3YxIRZFthCuXcePGAVBdXcXZM04YWvHn5eVx+lln6Y5x049moNW4/nC35D+u3hRxLFQTKbrMtiPPFfE4GWS1TjRTdUXKY4ZwbniLoj+9MLRjyevqpvxPL5BfXTVk1kpGdnfTHmomlWoqi6e2nsZ9r3+Wtu5K6iu6aBz/ZQBGV1YxUN/AFS2/DxZIDOP0iq3cXHJfXN9DuvHtZjizzZ4EQ69z5gNCZu2kmiyZCME1iyMGytNnAqUoMkxjY9Bv0Lo3udbflaN9dHTFZvxVjo61f+dVjDFUqC8ZrIxmMtusVTR+guYu56mtp3HbS1/C4wtmwLd0VbL3cHAiHzW6gvabl1G/5Ns43O6h1wSKijj3jpN4IYH5yK749mjMngRPv7CXig4vq15Lf9eYiEznN2Q7RU5H1pSnV4oiw+TnByf7QCC5baVe19GOLifHzDmBO5a0smh+p/ZJJmBlNFMmkvQA7nv9s0NKIkToa8jLd3JkweUA1N69nPzWFgbqG2i/ednQ8XjYFd+eLNk6GZuR35Ct720koBRFjtB1WO+rEjTtLeDapRMQm97hipeuh33tOGqr8V1+kalhqVZFM2UqSa+tuzLhOUcWXG5IMWhhR3x7MtiRbGaUdPMb4r23i2aaL+/Rhv17GoUhGuviNzvqc+ex9LEZiL1tCCkRbQcoemg1zg1vZUjC1PEsmod0RZrVrEjSG1tm3Y7LLt54roSbLm3gmtkTuOnSBt54rkT33HiTsd2kG9qbze/NapK5B1JFKYoc4Y4lrRQXxQ9zbJaReRMhO3+245tzGu5rFxKorkAKCFRX4L42ftnzVLjxjCcodEb2sXA4rC2mZiWhVXRnmxOkGFpF600U2ZxsphfCazS0N5vfm5UTebL3QKoo01OOEPI/3Lqynqa9LrQioMYTm4Nhtp3fKjKRpHfJ9ODuKjzqqbK6m39ZV0zXUpI112Rzslm29LIw289htbkvmXsgnfemdhQ2IfW803FYNL+TnRve49F7dsXsLopFH3dyS+x1TLbz5zqXTH+L569cyr9uuI6Nt97F2JrMRiWZSbKr6Euv7cJVGBlEkS3JZqdf2MuXb+qgcqwvGIo71pdUvoYZ782K1bnVJjGj90C6703tKCxke0fsJOT3w+jRozl06BAf7GxikgiWu06G8N1F8z4XjXVe7jznWRatWQvDkZ1ZW4wvU9RMKk14TvtgP/Oy8lFxzzOrjpOZMfHJrqKzPdksOrQ3ZLIxImvc99ah+ZIYrCgYaLVJzOg9kO57s1VRCCEuAu4D8oBfSSlXRD3/VeAnQOvgoZ9LKX+VaFyPL6A5SadLfwrjRpcOzyOPT114CU/84Xf8+dW3ufUrnw0erxgT89qBan0FctlVcNlVfUDf4JFzGPjUfTiX/xDR0gq11fivvzLYk/ooxEhyXv74iWxdej8ALc4aOsMm8fASz1p1nG66vojlN/u5/tznufWfV1O2fx/dY+p47ZolbLtgfsy1xg4mTpkZE5+KuSZXks1SMdmk+96smNSNTOTpmISM3gPpvjfbTE9CiDzgfmAu8HHgi0KIj2uc+gcp5cmDPwmVxND4DmH6DyKF12jINWv2HAA+2L4LiFUSv/nbx5j0qVMoHj2aaSeMZvXaUigoTvgT+PKVeDf/i8D2Nwn842kCc88x+nEdlRzp7cPj8VBSWkZxWXnEcy9uPzj086Pl+TF1nEDQd8TJ/U98kr+0fxIhJeXteznvJ0s5/sUnKXI6In7SSZzSc4ama67JZuyIYkrXoa5FIpNYuiYho/dAuu/Nzh3FLGC7lHIngBBiNTAfeN9GmTLC4UPBm2TMoP/A37V/SFk8tq6S65cW0ecOavrmJrj+OicM9LLwcp2m3YqUKCsO1tnq6+3hnGOCPSm0+M5+/X+TPkpYyl1DZT/yPW5Oe2glOy78bMR5gQSVh/WUSKKVda7sEJLFjigmKwoGJjL3JTIJJbpvAE48r3uovXIId5RVVK+S9SVXdxiqKWWnoqgHmsMetwCna5z3OSHE2cA24N+llM0a5yCEuAa4BmBMbS3NmzeaLC543b2mjLvnw/cA6MPFP9qD36joCJbcOJTXzfIfxkYvdfdJXn/dHXM8HtLnQ+bVDj3uFflsDHucSxiSvacPR+ch8PnBmUegcjSUFuueLjokhYWFeDwePtr4KsXF2ufee5+DgfhpLLzMyojHow5ui3ic7/cwzbNb87VHPD70mhueUOEKNg6KwpkPFR0JhEqD3iMODh1w4huAUY1eXEe2U1KeuSJ19967G5/GuiiV953n81DRsS3heRfNhDm/Hn7fzvxg++OS8oBhP4feuBdF20IGx7tlyW7d11V0eMmLc98kw7Sz4eITYH9b8F7Od8GYsQFGVwAGrOnZ7sz+C/B7KWW/EOKbwCPAuVonSilXAasAjjvpFNl4vPnpmM2bN2LGuGXVTwNwTE05Z9YGv4LQjuLci2YgpYbJSkgGtgeL/4l1zyBWPgD72qGuFrlkMXL+3JjX+Lv249nVPvR4Y14tM/3tMeflAolkL/jVH3A994+IoGHpyo+bj1FYO5n8fCceD9QfezKlUeanEO9uc3Lb94s0zE9BJrCb3Qyb+bwNjXz01uaIc+LdO/F8F9/59ISYxkkACGlZ/aXoXczKlS9zy61nZ9Ss9d7GEs3V/Zdv6qC4KjkZKjq20VVlsGB3FRRPGn7oHfyxirtWNmj7MMb6WLG2hVEHtzHNpLksne40dobHthIpewPDTmsApJQdUspQhtSvgBkZks029DKwQ8fFumcQS+8azsDe2xZ8vO6ZTIqZVTg3vBWjJMC8hMN5C3zcttLN6IoAEBnWXExvRFhyoKiI9puXpX3NEFbYzRORqn/AzMSykex/CUfPh3HC7D5uurSB5q0uTmwo4/i6Ms4/rZT1a+xZ29upKN4CpgohJgkhXMBC4MnwE4QQdWEPPwN8kEH5bEErA7u4yM8dS4I6VKx8AOGO3CsKtye4wzhKKXxsvUb6YRCzEg7nLfDx6vs9rLjfTV1DACEkdQ0B7r7yDS5reBUpBN6GRlpX/izlWlFa2JH7kIp/wIochNMv7GXF2hZWvbaHFWtbEiqJTJSyMBsthfiJi3v459OlQzuNgF8Agn0tDm5bUmSLsrDN9CSl9AkhbgCeIxge+2sp5RYhxHJgo5TySeDbQojPAD6gE/iqXfJmCq0ciYjKsPt0zC9723DM+XSEOYqzR/wGDIivDMxOOIwt/DeTj9ise3662JH7kEqWsxU5CMmQy0UBowMSbrq0QbdXeTJdE83EVh+FlPJp4OmoY8vC/r4ZuDnTclnJ+jVOHvsfFwD/9ctaxlfU8cW5kb0pFs3v1C8ZXlcLe9tijwsQoeN722DpXThuuQGSzKNwbnjLklLiVqJbfRZGRMJhpiObUon+sbvWUjxFFeNINgErS5on+swy2TUxhCrhkUFCiVu9PcEv+nC3k8V3nsDvn6lL8Mph5JLFyKLIdqxSgIiqCCLcHvLufyQp+Zwb3qLoodU4DnYhJDgOduVEBVrN6rOA98Izs17JZSPR5hBnPgn9A3b4UsLJpKKyuhBfos/MaNdEM1GKIoPcd3dhTORMn8fJsvunGx5Dzp+LvPMW5LixSCGQ48ZG+1eHaU+uXES8TnPZjGb12W9/mf5vfMFu0Qwx7fl1LLz0LL4x+xgWXnoWu37yge229nD/QP1kb8LVst11pDKpqKxOBtT6LEPY0TURsj88dkSht2Vsbi9Kahw5f25EOKxjzqe1zVG11bHH4mB2p7lMmrEyUX3WCsrXPM55P15Kfn8wR+bJtrO5b83Z9A3+a2ZTc6F4GPWlWGWysSJZTg+rdy/hnyWAI08S8ENdg31dE5WiyCBj6yX7WmKVRWNtcol00cgli2HpXRHRULKoEP/1VyY3jomd5kJmrNAORQyasdwwIsxB5WseT6llajS1dy8fUhIAS7mLPiJ3EJl0CqdDIl+KlSW3zSgKaJRMlGsPfZajDnr5V0t34hdYjDI9ZZAbb/ZQWBQVh1/oY/n1W9MaV8scJe+8JelaT2Z2mstVM5YRytc8Tv2Sb+NqaUZIiaulmfol36Z8zeNJj5Xf2hLxuAnt4INsaMBjhHghqlabbJINp00Vu81sybB+jZPzTyvlhHHp5WGoHUWGKF/zOP9+93Ia3HO4TpTTLWFUmeS+7703GPUUWz02GaLNUcGs7B1JjeGbcxpuMMVcZLYZSw87orRq716Owx25C3S43dTevTzpXcVAfQOuluGqNONpYg8TY87LhuZCiUi0Y7A7Msossr1cewitqse3LSkC3Embr0asopABCyIDpEx6XOEQQytQh9vNFTzGCzJYi+Qnczfyxbmnmi9nGphl6zfTjKWHXeat6F1AouPxaL95GWO/++0h89Od3MI1/DLC/JStq9VoEuVSZHOHvWTRM7NZGTabLFrBM6nmYYxIRVHodDClqjDxiUlyIMlxQ70rolegBwZ/j/nr3+F715gpYtbgWTQvYhIH8xspxTNvWenYjt4FhB9PliMLLmdLWzdn/vK/KG3fy2dqX2HL7Ff4xWvnZ8VkkwyJdgyZdDjbgdVtT5NFL3gmlTyMEakoso3olWZo/eTqPJRxWTKFmWYsPTJl3oqm/eZlQzvEEOnUeNp2wXyaL7506PEkYAXJ707sJtGOIVdMNqlid3Z6NHrBM6nkYShFkQH0VqBUjux+1npmLLP8Cpkwb2kR8kOYEfU0kjCyYxip/TPA/uz0aG682RPho4DU8zCUosgAWitQAPm53C8vkSxm+hUyYd7S48iCy486xZDI/j7SdwyJyDYfTNBh7Tal17tSFBkgegUaKCgAjwf5iSyvVmYBZvoVzDRvSZn5sgi5hFH7+0jeMSQiG30wsUUsU0MpCosJRUkd/uxlHP7sZUgp2XL68dDaytiiPDy7dlA4aXJEO9SRjNl+hXSjtEaVj6K7u4eujoOUlY9KeZxUWb/GyY+WN9K135n2CtzKiJtk7e/ZFP2TKUbyjkopCgvRipB6//332dvaytjaWo6fMpH+3TuHlMXRQCb9Cu6m+B3g3E17mN4whpbWVnZu28b4DH8H0XHuqUTJDE3IbSE7eHJjGZ3Qk7G/a+0+Hr6tmodvq6Zy7MiZPLUYqTsqlZmdYT788EMATjthOkJkvlyw3SSb/e3c8Bal1/0Ax85mSq/7QdKVbA/s6tH9ARg/tgaA/e0atbIsRivOPZlM5YgqpgggubGSqYKaTNE9rd1HSL7oa+Ris6GjkRG5o+jo7OT3v/+96eNu/+gjdu8x1qc4Ly+PiooKKisrqaqsxOf3c/jwYf724osA5DtH5EefkGT8CtGOb4cFCXXCYZ+y1otnNxoloz0hGx8rGXNSMvb3RPKHK7BsyjtQ6DMiZ6s9u3fz9a99zW4x4lLijJ0k/F37AdL2VYTGiTa9BOorcLcaU3SWMmEM3Td/PfKYhpmo+jdPaDq+i37+W/jZbwhUlNEzdw6eGcemLMqo0uAK9vn1T3DxZz+HcDhASgKBAH6fH5/fR8AfuWp2FRRSUlpCvsuV0jUDgWCdoNpxftpaHUTvBoxGyRhRKPHG0jUnteVx06UNESaiaPt7SVkABDx8ezVrH6qIOFcv+if62nqKavU9lSPSzm8Ut2+4jlTmvWbajEhFUVFeyoWzzY8oOuAJUFNozFrn8/vpPNxN5+FuOnr7yc93Mqogj1GlJUxuHMf3v3lFRC2m8L/TzSn37NoxpCRCJhYAX00g4nG2M6ZLu2qmGAwQyOvqpuzx5zlywMPh6VNTusbiz83lt8/8ndc3vMwZ0xuTeq0zPx+Xq8CQCdHvG8AfCOD3+YYUxTANwFXAEvILirnk6g7cvgBFzvj3WuIJWdLfJ3jjuRLNiVb/9UKzlWjI/p4oAkpr96F5bR1F1XvEQe+R1P022UY8P1C4UgghpSR/1yZefuFZPnh3E67i4GJGCGGbuXpEKorG8hLuPd/8ftHv1Z/MCa3vJPWaovETtJ/o1o/ySbaYXzhaCiJbGLX1I2pff5P87h4GykppP2NW3Al+oKwUV3f89+Hw+ah9/c2IcTq3Gvv8OrfC9Itg9d3f46o7HmD/gWBxFZ8PvF4HkE/wXyS46h81SlJYIPH0e+jp6cU3MIBvYCDOFfQJ/cMHw3JbgNspLfNz6103M+/zRby4vTehstCekENhvsFdSu+RPN2JNtGEHjIRzbnHwU3faBia6PrdIq7JKmL3EeVkh2GTVfB5bUWlN7ZVWBWlFU+pnnheN0jJuZMj+8bs2v4Rn7kyu5pujUhF4ev3WzJRJrsir5lUaroMRshWJVH/0is4fMFkH1d3D/UvvQKgqyzaz5gV8Ro98jWUSWt/WUKZ6guCO5azTjme7X/709DxY+acQNPegtj3UNLPzg3vAcEJ3usdoN/rTXgdgH/uOsgnp9eR73TicDgiFMVNP/8d/3XvfVx55SEuWTAACM6bUs2L2+N3KNQKx+x3C3oPR67U9Sba2Ak9drXa2ZZHxz7n0IQe/K2dcxK+QwhXGPEmYW1FpyGHhdnNVtZoiucHOvG8bs6dXB0THdm5I5iYO3HCBG649mpOnViDlBKrU33+7YprdZ8bkYpCkX3Uvv5mzISvtRsIJ3S8bsM/4o49UGauQm7ep+17CD8uhKCgwEVBgTE/RXFxH4UFscpHCEFtbeo+qehwzGtma+9g9Sba0OtvurRBc3U/6LKJQtv8oecP0QsZNaro4o1tBlbWaEqlrEco+bO6uooZp57CnCn251ep8FhFRtBa9cc7HuLw9KkE8vN1nw84nbSfMSst2aJprNPeJYSOi3XP4JjzaRxTZuGY82nEumdMvX46pNo7Wq8ZT4w7ZYhI7ZFqBnJ0s6GF/96Z8aZAVtZoSuX76OzsBKBi9Oi0r28WSlEoMoLeqt/IbkBPmUig9ZyzU3Zk63HHklaKiyL/kYuL/NyxpBWx7hnE0rsQe9sQUgZ/L70ra5RFqt3XTr+wly/f1EHlWB8ISeVY3+Bj7QmtpDwQc64ZNn09Oaz0T6SqXI2QyvfRtm8fAGPH1qZ9fbNQpidFRtDyNxjdDcRTMmYrCYBF84MrultX1tO8z0VjnZc7lrSyaH4nYs4DEb3JgeDjlQ9EdBiE4M5DrHwA9rXDvfcitmyKOcds0ikjoWciig60cRUGWPjdTssm70xnN1tZoyne9+HWcb31DRYPLSmxx8ephVIUiowQmtCTiXoK0X7GrJjZygqTUziL5ncOKYwI9rVrvyDq+NDOI6RUBgYQ378LICPKwqyJ9vQLe3Ht8lE51hcz0cVzUudSrSerazSl+n1kU+UGWxWFEOIi4D4gD/iVlHJF1PMFwKPADKAD+IKUcnem5VSYw+HpU1PaARyePpWBslK8ZaVJKxkziNgZOAT4NcJP6iLNBGKl8Z1HtlNSHmDF2shGSvEihSD3Mq5zqUbTY+sqNXe7VmKbohBC5AH3A+cTDCR/SwjxpJTy/bDTrgK6pJRThBALgR8B2RVgfJSQbA6E2fgLC9l25RUZu16ImJ2BX8YEcMqiQuSSxZEvNLjzyFXiRQqF/tZ6Llcm42zlsXWVXLt0An3uoKO9aW8B1y4NRrpZqSzs3FHMArZLKXcCCCFWA/OBcEUxH7ht8O8/AT8XQgipmgeY1iXOCKnkQOiNY6eySQXNnQEg8xwQkFBXi1yyOHaXUFcLezUKDdZlj4MyHVKJFLKr05tV2GFeu3Vl/ZCSCNHnzuPWlfWWKgph15wrhPg8cJGU8huDj78MnC6lvCHsnM2D57QMPt4xeE5MJpIQ4hrgGoAxlZUzHrn3p6bL7C0pwdVr/EZwuhw4UqwHFJeePhwHOiMD3IUgUFNJwOXE59WOaUxW/hAFBzsQGnGS0uGgv7pK4xWx5Hk8weilKJkHykrxFyYuWpKM7D5PP95A4oA+lyNAYXkReWXlCL0ije99oD/ACXFqTB06DK37gsoE6GlooHRvK9TXwejICj5/XLeeBx54kAULFnD1tYuH/DFHPD6SqVnYe8TBoQNOfAPgzIfRNT5KynXjWw2T5/Pgd0Z+R607XPg0ktKdg5HMes/VTzaWoGgmWvKnS+8RBx37nNG3M1V1xj/zgITygjwKnA46O2HvXoHXC//855/5859/zqWXfpavf/VrlBYO35ub3ivWHW/GCX0pvx+Acy68ZJOUUrP20YhxZkspVwGrAI4bUyMb3nzNtLFDK+HXfnAbs2+/zfBKuGZSqX4JjzQo/e4PcGj0dAhUV3Dg5q/rZma3zJpNKp/LcT//hWaKlQS23PBNQ2NMe+R3muU4vGWlhkxKycjeuXWHoczs6oJupl90EhWfPFe3EKPja1chNHYGctxYAhv+Emf0MYjW7Yh7gr6Nv997L2fTi5wZe9+81dgAQN24cTQcN3Ooou2L2w8mrPcUItpnAMHIHTNCSys6ttFVNS3i2Hsb9a8HsRnXoeeKqzJvetKS3wjxdgw3fUM7QbFyrC/Gn6OH2xfg48dUsfGFYq5f7KSvL/Rf9i8Aug+PpbTQGZFwd+XXtKsGjB83XDXACuxUFK1AeBW2hsFjWue0CCGcBIspdmRGvCDJmF2iTSvuT58Ng4rCDFPR0BgaSgJS7xKXCL2aS8lkRKeacGc3csliCPdRoOOT0Hrt/LnDJqnt+5EWZthamV2shZFIoWyPekoUtRXPIW9mkt6yZeFKYpjX34ydnu9Y0hrho4DhHB8rsVNRvAVMFUJMIqgQFgKLos55ErgS+CfweeBvmfZPGC09oaVQnH98Hs+gaSa8r4JIoa9CdG8GLazoEgfp5UCESEfZjNr6EQeOmc5xP/9Fxn0bQxN9KOpJzydhM2ZNXFqT50Waxoj4kULZHkWUSBEkUrx6lXdTSdJradY+3qOxhoqX42MltikKKaVPCHED8BzB8NhfSym3CCGWAxullE8CDwO/EUJsBzoJKpOMYnQlrKlQBnwUPrYeQLOvQuFj6w33ey58bH18JRGnS1y6pJMDESJVZRNSwDsuvBhB6o70ZIgIhx1UDPHNTPZjxsSlN3nO+bUDjLmihsaxczcRff177tkeI38iRZBI8ZqZpNfQCM1NscdLddZQujk+FqKrKIQQTwOLrcxbkFI+DTwddWxZ2N8e4DKrrm+E8JVwJ5VMZBdNjKdRtLB46wtcMj3YmlNPocQzByVjKtI7VwKyOsyUlaBPdKqkmgMR/npIXtmkUkwwHWLCYfe2wdLMJMqlgxkTl97keeiAk+JJxsawshJrqtfv2Ofk/W2RPTkSKYJEitfMJL3ly31RPoogZ8yKXzU5k8TzlP0P8LwQYqkQQr8q2win/YxZBJxOfscX2cME9jARiYMmOZ7bXvoST20N7gj0TCiyqkLXJJSMqUh3jOoKeh683bLQWLNINTQ2074NvUQ5sfIBS65nFmbUSNKbPLUimPRIlF9hNVrXl5KY6yeq72SkRlN0QcNUFeHChQHuf8BH43iJEJLRFUHr+tSp6UesmYWuopBS/hE4FSgHNgohlgghvhv6yZiENnN4+lRazzmbW8QKAlEfl8dXwH2vfxYYVijhBPKdeBbNw7NoHtIVqWuTNRWZMYZdhMxHru6eCPPRqK0fJXxtOsUEUyKHE+XSnbj0Jk9nEstEKyuxmnn9RIog08UJFy4MsG2blz63l1tvta6keqok8lF4gV6gACgDskfFZZDD06fS/EIjsDPmubbuyqFzgJioJzG40ndDWlFPvjmnpT2GXaRjPgr5NsKxtM5TDiTKTX7uCU57aCWl7XvpqR3HW9cuYceFn017XD3z1egaH0azH8x08qaC0esbMR1lu0M+k8TzUVwE3EMw8uhUKWV62Rw5ztgybedR+PFoO37NpFKKBv/2zTnNsONaDzPGsIN0zEehz1M6HEiwPOopnXDYdDly+DBSSoROYyAIKok5K24h3xOsMFrW1sqcFbcApK0s9CbPkvKAYUWhp2xOmN0XbI5ksYNb6/pCoOmryUZF4Pf7aW21NtQ1FeLtKJYCl0kpt2RKmGzmxjOeQIhjIo4VOvu58Ywn4r7O3bRnKOnObZGjOdtJNw/j8PSp9FdXGU7uS5aA1wtd+8mrGGNLOOyo8nIAfvOb3/Cv97fy3VtvZ8YZs4FgUlY4Mx/8yZCSCJHvcTPzwZ+w+bzPpC3Lied1x06eSWQuhV67+qeV9B4enqxf/UsZ/oGgArTSwa2l7KrqfJw+O7sUQuh7fXbdGn607HscOnQIgEAgQGCwCsKo8sRJo5lCV1FIKedkUpBs55Lpb7G5bBR1ZR20dVcytqyTG894YijqSYsDu3qomVQaoSAy2c+6c+uOiMe+E2fEHMsEOyZMYNr7H5AXVgbE73CwY8IEw/JYJXvw+3iVik+ei79rf/Dg2TPg7IcjTww9lyLS5xseP4ovzZjAwRu+yj2PPcm7m97kykvncv4l87nljh9TM3ZsxLll+/dpjlG2fx/nTamOvW7AeNqRcAhe3H4wRjmNkrEKK8TG50tYv6qSrv1OKsb4mHdNJxDA6xGESicG/47E63Gw5sHRnHhet2H5jHLied0R4xYdCnBYR3478b3/Kjd962r8/kiz2KSJE/n65y7m+s/M5p0j+vdNJhkxJTwywejCPp6/culwBM8LPQy8Ht8UkknFoEV4KYuCgMNQaQvTZagso2tqESft3kJxv5u+giLenXgceyobod/YGFbJ3rl1BzWTTqLr739Lu9xKvOx7mVeLZ5e+Q3zJVy/jm5ddwn1/fp6Vv/wtLzy1jorKKr6/4p6I8wbGNeBqjc3QGhjXoKkUplQZr3G0vcPDucdUDZUQCdG8eTfHaSih9Wuc/HFlER538Pyu9nz+uHIMhYWSgf7EpUcO7XdqKjez0ZPfTmRAcv4XluL3+/nuN77EnUuuH3pOdHcghMCza0fC+yZTKEWRJGZVUj3a2FPbyJ7axsQnZpjK6ZOHdn7pEJ05n2z2vWfXDsomTeYHN15Dh1fwwEOrOPaYxtiJ/s4fIhcvRvQNuwxlcTHc+cOklIIZ3Hd34ZCSCOFxC6IsY7qMrT96i0ALh2DGGbN5as3j+Hw+8vPDpuLKWvxd+ymcNBmasqPEjVIUSZLpBDBFfCa0N8fuVGxQSFqZ88lk3xdOmjz093ubg27BU049Nea8wMKFDADOZcsQzc3IxkZ8y5cTWGhO0YKQ+SmcsR5fzDGAfa16O7zEJW/z8gMcPhLg+HFlQyarmRdY40fQk99uvnbtt3hqzeM8/Me/8OObb8QZFl6fVzEGf9d+REEhZEEYkVIUSZKrxe1GIhPam5n10f/hDARtvCX9bmZ99H8AlikLPfOSXuZ8Mtn3oQq2vb3BmaGqSrtuRmDhQrwmKQY9wqvWOgSaVWz1QlG1yHMGKCyR9B5xUFIewNMr6DsSfG1Xez5/+EkNrjyHJVFIevLbidsXYPpxJ1BcXExvby/93oEIRQGD90P7XpskjEQpiiQxo5KqUXKx0U8mOWn3liElEcIZ8HPS7i2WKIp45iVZVaFZ1VeW6PcPyHW0QlG1kXz11uFktZsubaD3cGQCnOqAp03n4XyO//aVtHSU0VDVzbJFr3H5nMSJqmaTXWo2B9DMwLYgASydbOajheJ+bWO43vF00TUv/c8a6PeiZXEXnn6cG/Qj44zgWL0a17RpFBQV4Zo2Dcfq1WmNZxbR2csOh7bPoXKsP6k6S4ogj62rpGlfEc0Hy5FS0HywnG8/dB6Pb8j8YlHtKJLEjEqqRtDzhdS98g+1yxikr6CIEg2l0FdQpHF2+uial7p7da3ywucPVhD+VGqlVhyrV5Mf5rwWTU3kL17MAJjml0iH8KQ1veZJ0cludmdvm41V1XJvXVnPt78bWVbW7c1n+WOzM76rUIoiBdKtpGoEPZ9HXn8/zv5gTOnRHnH17sTjInwUAD5HHu9OPM6S6+mZlxK5btNpKOVctiwiwglA9PXhXLbMcj9FshitqGpmiW67sbJabvM+7TbKLR2ZD3FXiiJL0fOFRE9KR3PEVcgPkamoJ8+ieTHNoySJFUU6DaVEs3ZXG73jdmOkLIaZJbrtxsrOgo112oVTGqrMT1JMhFIUWYpWox+9SSlXIq6sCGXNZH6GVmFGPP2IHv34xXQr/MrGRkRTbFcb2Zh9OSnJkI11lowQbWbqbLPO33LHklYORrl9ilwDLFuUfN/7dFHO7CwlVN7cW1aKBLxlpfgLY5uqg4Ult00kFMpa0u9GMBzKOqE9O1fGevjmnEbPg7fT/fjP6Hnwdjxf/1xs+ffBn0B1Be5rF6ZV4de3fHkwoS58/OJifMuXGx5j9WoH06a5KC5yMW2ai9Wr1b99KoTMTJ1tTpAibmiwGf6WRfM7GV/nprH6CEJIGquP8LNrX7Ql6kntKEwmPKTVX1gAMuhXSMXxHO0Lic4KB4tLbptIpkNZM4XV5d/TTbBbvdoR0T2tuQmuX+wEfCxcmH31j7IZLTNTcI8fudc3099SOWqAzQ8+YspY6aAUhYlET+ROz3AhIzMcz5mKuEoHPfNSpkNZM4nV5d/TSbBbtiy2xWZfn2DZMicLFxotHm4OdvfSTpd45qTKsb6cfV9GUIrCRLRCWsMxw/GciYirVImXKZ3pUFZFkBYdy57ecauwu5e2GeiG9Y71s2Jtiw0SZQ6lKEzEiFM5v7uHaY/8Lmt3BEbQ2zXEMy8lE8qqNb5GzzlbiVcpNptoaAyam7SOZxIro4MyxUgK600W5dUyEaNO5VzOto7nlI5nXtpT28ibU0+ht6AICfQWFPHm1FNi/BN64xf4MmsmiUeolIfjYBdCgmOwlIdeBrZzw1s4mvZSdvm3Kb3uB2lnaifD8uU+iosjQ2eKiyXLl+vvfM3kjedKgp3tLIwOyiT5rlCogqRklN/SPtrZhNpRmIhWSGs4WuGtuZYHEW/XkMi8ZCSUVW/8on4PR9KU3SySqRQbUircdRJCJl9+PF2CDmsfy5Y5aWkO7iSWL8+MI1srUzuaXMnG1novA/2Jq+QaRcrsLrmuFIWJRDubo6Oe4lWenfbI73LCDBVv1/DP6TPTzpTWG98hsydCJ5lKsemWHzeDhQsDGXdcg16U0DC5ZLYxy3QW7tCvGyfx+4PKJpGiCC9DbwdKUQxiVqXWeM7maY/8Tjfb2u5yHEaT4eLtGszIlNYbPyCyx0oqS0sQ3bGTgywtiTlmRvlxOwif0O69dzfvbSxJ2sSib1aSVI71c8LsPtY+VMHDt1dnfbSQGYUMo3cl+1qH28Ua2VGEytCHI9Y9g8hAf3dbFIUQohL4AzAR2A1cLqWM+c8RQviB9wYfNkkp0+8er0GmutYlMk2lYoYyQ8El09chkVM63UxpvfHdBZnt3hYXvX9qjeO65cfTKOthNRufL+EPPxme0HwDpBShFC9KKNoxnG4UlNWht2YUMtTPw0gNse4ZxNK7EG5P8MDeNlh6F4DpysKuZdpNwItSyqnAi4OPtXBLKU8e/LFESUD8rnVmEp1trUUy5TjMKkUez+8QjVGndKrojd/v1C6QZgeiV7tkh9Zxz6J5sZnbaZb1sJr1qyp1zSzJcOm1XbgKI02GIXNTPFNOsmhlTP9mRRVvPBe7w0uVeO/FKGY77sXKB4aVROiY2xPcYZiMXaan+cCnBv9+BHgZ+H82yZLRrnUh05SeGSqZchxmtWVNNhnO6vpKWuNrFy+xh2R2CaHMbZx5SEFWh9KG6NqvPS0kO9HFK/738O3VplwjNL7VobdmFDJMpiOgIfa1J3c8DYQd3nYhxCEp5ejBvwXQFXocdZ4PeAfwASuklE/EGfMa4BqAMZWVMx6596eG5Sk42IEIxDpLpcNBf/VwO0pvSQmuXnNuvDyPJ6iIoj5/f1EhA2XGyggX7j+g+5xnTA0+Tz/eQFhLy6pRBDoOx5w7uveIprM4IBwcKik3JEuyFPi8FPV7cMgAAeHAXVAYd9egJ3s6uBwBnIP1s5wuBw6vD0fnIfD5wZlHoHI0lGp0qOvpw3GgM/K7E4JATaX2+UCvyKdEDmg+ByAKChFOJxw6zLX/eRNbm5p48D/+g+mf+ARUVqbxLo3T7wuAEHz4vsA/MGwSaWjooaWlFGc+1E82xyneusOFT+PjSOUaez7Uv28mfMxLns+D32m/6bL3iIOOfc6I22bp0kvo7+9j/Zo/UjLYDbHzkJPWtny8A4LGxm4c/ZKqKoL3RzgfbocBjQ8xPx8+NiVp+c658JJNUsqZWs9ZtqMQQvwVGKvx1NLwB1JKKYTQ01YTpJStQohjgL8JId6TUu7QOlFKuQpYBXDcmBrZ8KbxCot6NZRazzk7YmXeMms2yYybiLqXN1C5+f0IK6XWdfXQ25V4y0rZduUVdG7dQWv/sNIpWHQJ/Y89FXN+YZSPAoJ+gTennkJ/2Mo+3OHd73SBlBT4B5J2Wkf7RMKvpzeGnuzpUF3QTeX0YDRJY2cz5X96IbKEuCtfu6hfETj3vBObcDf+NPBrl4DemFfLTL/+Sq+wdjLOVzYhlt5F2aA5YcZ//Rczi4sZeOCBjDQp2t7hQTgEj73i5g8/qRlapa9c+TK33Ho2X76pg+IqcxZK723UbnKUyjXuWtmg4wvxsWJtCxUd2+iqmpa2zGlTBe9vi4x6EiK4g5p9TDXlZaU8tq6Sa5dOoM8dPL5y5ct8/5YzefD7m/nSokjzsNiyCfH9uyLMT7KoEHnnLcgpsY7vdLBMUUgp/03vOSFEuxCiTkq5TwhRB+zXGaN18PdOIcTLwCmApqJIB7tqKJXtaUorr0LLOZ5KkUAj0UrRk3thWAJcPOe3FqkUCCzwebnwjWct6ztR+syGpMJYrajvpGlztqFJ0cwLenHlOYYmNGc+pieWxTPlJOuYzqWM6VB5dbcvwLnHVDH7Y+AJ+8pvXVk/pCRCuL35LLt/Ol9a9H5slNOCS+Clf4zMqCfgSeBKYMXg73XRJwghKoA+KWW/EKIaOBP4sVUC2VFDKV3fiJkKLpHfQWtyDyeZSrDJ+kQmtDfj9fQNhc2GFFP14Q7qu9pMUR6OLu2dQEbDWHVsy3Y0KQrvF1HR4TVtJ6F3jRCp1IQaSY2Q9LraNbcXaUc5rXkquIOwQDmEY5eiWAE8LoS4CtgDXA4ghJgJXCul/AZwLPALIUSAYHTWCinl+zbJawl6XeyScWhnSsEZqfJqtBJssgUCT9q9heiiF86An6ltu4Z2ZMnuaqIJVJSRp6EsMhHG6tzwFvnf+qFu2G2uNylKBiOOab0dRy4qhmga67w07Y0N3WisdetGObHyAcsVhS3hsVLKDinleVLKqVLKf5NSdg4e3zioJJBSvialPEFKedLg74ftkNVK2s+YRSDKQZWs6WjU1o+Y9sjvOO7nv2DaI7+zrG6UkSqvRivBvjvxOHyOyO11vAxuPQUUbbbTC+k1Qs/cObaEsYZKfIi2A5oR9ck2Kcp1EiW2ZSIU1k7uWNJKcVHkzr3INcDy67dmNMopGpWZbSPpmo4ylSgI2olw4SRTqiPZDO5kSpGn2t/CM+NY8qurUqoIm04lWa0SHyGeLC9n4DvfQU6dCps2GX4vUkoCgcDQj1FcNROpCIvys4NEiW0joQptiM6Og3i9kRFei+Z3AkFfRfM+F678AD+79kW+ODcAD9YGzU3R1NVaLqtSFAkIz3w+cM90Rm39yNRJOB3TkVl5FEaIntzTiXoKjWf0fC0FpNc/PNn+Fp1bdwxFPnVPGEP3zV+PPKFpT9zXF276gMI/Po9jIPg9iINdFD74e7oPduCZcSyFmz6g9JkNOJb+gJI7b6dn7hw8M44den2ZRj7GscBG4I4jR7hj+XLI0I7CVVDAJZdextQLF1I/ZVjGURLcvszU2rrk6g5W/7iGgf5hZZBfEOCSqztw+wJxdxx6MmZSfqN8tOk17rj7P+nv72fqlCmUFA/ft184+0O+cPaHAPyj3ceMcXuAyfiv+xJ5d/43IqwhmiwswH/dlwh0acYDmcZRpyiSKXkRvWIXgYCpK/Z0y2/Ec4Z3bjU9OCytRDujtaT0rlteWExvQdHQ61srxnLM/ibdUiJGrtfaX0Z9QdAvcWBXasmV0/7yypCSCOEY8FH0l1c4csBDTdj9k9fVTdnjz3PkgGfoe67Q8FM9DMwbXc7DM0/j4MGOlORy5DnICwwggGCqUny83gE2bf6Atat/C6t/y8eOO4HikqCvrL+vm4JiY7k9ZlBfL2htcTDghXwX1NcH2PKcZMtzkJ+fx4BGmkV+PjzyH2G73bC37O3twVWSPX3lA/4A7256EyklZ37iDB699To40kH4Xt2zawfupj3460/G3boHd9MeKIbCBecFFx5d3QQqyoILj2IJf/+bpTIfVYoiWVONlSt2M8xGiZzh4TkUdpJMLSk9+p0unjz9oohjB0dVaSoDM65nlHjKuuGvLyGiHNThpWFCi4To3VFevpN5X5nPZ7+yEMczL5F3/yPQfhBqq/FffyWBueeY+h5CfNTUykNPvMj/rnmKD7e8l/gFGWDAC7t3Bn8Snfe2uRV3LEUIwdKrv8gtV32R7n/8na4PY885sKsHX00gchFT2QhXLIo8McVFTjIcVYoi2YnfytIeRmRJtONIlEcRvap++fLz6SfzpJI3YQS9HY5V19NCT1kL0I1iyh9cFIR/b6EzB8pKcX/6bMSc0+DR1UFHd8iH0XaAvB/eh/dAuyUlQKZOmsy9P1jC9+/8Ee9t2zFU0XTL5s0cd/zxpl8vVf72ooOHH85j/34YMwauusrPueeFmZaiPvfNmzdzfBbJD1BfU8Vk3z48u4I7/1R3tJniqFIUyU78ZoSvpiqLkR1HPGd4zcuvMvWjDyNW1SWePiramy2t06RFsnkTuXS9RBWBNREi5nzBcEZ9zaRSirCvl0V5eTlnnnnm0OM8h4NPzJ6d1piO1atxLluGaG5GNjbiW7485Wzzs86CZT8wfn5eXl7a8ptF+OdAbTW+yy+CCeZmUVvBUaUokp34zcp8TkUWo7sfPWf4pO07NCOUrFhVJ8JI3kQ6PoxUrmcW0co6kTcg4HQidJRK9OIhV3tZRONYvZr8xYsRfcHquqKpifzFixmAjJQmsYto5Ri46CLyfvvboc+BtgMUPbSagc+fHzQpZTHZ0w0mAySbtxBdFlw6HIbrMKUrS7pmrwKPR/O4Vav4eCTKm4jXh9uK65nN4elT2XblFboLDjnoTPaWldJ6ztm650Uf10v2y+ZeFlo4ly0bnhwHCZUmGamElKOjqQkhJY6mJvJWrYr9HLwDlD/2tOV5UOlyVO0oUslbCF+x91dXmRZ2mkiWdM1e/YWFFGooCytW1YlIlDeRyKcwob0ZT+8RznllraHdhhmd9lJBbwfaes7ZeMbUsO3KK4aOG9mpehbNi/RRYE4SoKG8j/4+KNCuhJsseiVI7ChNkik0laPOuaHjdne5jMdRpSjAnppOesSTJV2z164pk5n6/ocxE7BVq+pExAutjedTCO02XpULI3YboTFTuV44rf1lEJZLkQ5GFyJGzwv1skg1mU+LoUzwQeUjDnZR9NDqYM+Mwb7M+Qd3MFBtXo9m2diIaGrSPD5SSVUJWpUHlS5HnaLIFdLN2j5QV0fXQFHEqrq3sJh9GfZPGCGeTyGTEUzJoBeRZnQhYvQ8s6vUxnOQ+75ijb/At3x5hI8CRn5pEj3laAQrGqaly1Hlo8g1Dk+fSvsZsxgoKyW/u4fa199Myoa5p7aRJ0+/iNVnX8qTp1+UVe1Ew4nnU8h0xJQRzGpBawd2OMgDCxcGe2qMH48UgsD48RnrsZGI1asdTJvmorjIxbRpLlavNmdK9C1fPuSbShYzoirNRu0osphM1nKyEz2fAoBEIDQ6jNvhawmRydIpZpNMG1czCSxcmNGeGkZYvdrB9Yud9PUFJ/TmJrh+sRPwsXBheiU/AgsX4n/tNfJ++cuIpEuZnw9CILzaXfzMiqo0G6UoLCLd8hyQ2xNSPPRCYUMKY0J7M6duf5cC/4CmA9DMCKYJ7c2cumczBS/81fD3lMke62YTz0E+UiaD1asdLFvmpKUZGhrhp/don7ds2bCSCNHXJ1i2zMnChem3fPX97GcEZs+OyR8BcH7/VkRLK7K0GPw+RF9/xhqmpcJIuTeyCrN2Ark8IemRqLyGVpvUcAKIuC1T05HF6PdkZSKm1cRzkI+EyUBrl9DUJLjx23k882zekPJYvtxHi46/We94KujtpLyXfgbHR/8cqumU7ZnZykdhAfF2AslgNN4+l4jnnNZ7PhyBNM2JrXUtI9+TGX1E7MQ35zR6Hryd7sd/Rs+Dt1tSDsQoZvsItHYJgQD88pd5NDcJpBQ0NwmuX+ykslJ7jIbsi/ewHaUoLMCsnUCuT0haJHJOJ3JSm+mb0LtWou8pOhEzlEiXjSaDbCa0+o+ewNNRFnq7ASljTUxSQnFxpP+ruFiyfHkS5ViOEkbCbjPrMMs0YWZP7GwhUXkNvefB/OxqvWsZ+Z6yKR8nV7HCR9DQGDQ3GaGrC379P74If8by5ek7su3EDN+oFmpHYQFm7gRC5SG23PBNtl15Rc5PTonKa2g9LwmWwTDLNxFPllzfsVmFY/VqXNOmUVBUhGvaNByrV6c9phU+guXLfTG7BD0aGmHhwgDbtnnpc3vZts2b80rCqrBttaOwgJG4EzCLROU19J7vKhlFv8kJdqFrnbpnMwUej/qe9OjstKSon97qP10fQWEh9PUFlUVVFdTUBE1K4buXkWhisjJKUikKi1CmCX0SldfQer7AQll840ebUsIjXcLNBrI6/XIdZiH27tUt6pdObsTy5b6ICCVIbwKPjngCcLslJSWS+x8YWSYmLayMklSKIsNYZUNURGJm2fJMENN2N6wGk+3KQic5LN2ifsGJWn8Cj86HSDS56/k89u4VXH1NwJTciGzGyrBtpSgyyNGSaW03mWyFahZaZoNMNCkyhEu79IsZRf0WLtSewFPJmtbzbejouawkeiG578RTDb/Wyv45ypmdQczKr1DEJ1GuRjaiZx7IhiZFctw4ZHFkyXGri/rFi4jSQ8+3oaPnsg4tZ3R+d49hZ7SVYdtqR5FBRmKmdTaSjYUEE6FnNrCqBpNWT4pQmfEYKisZeOAB01qZGiGViCg9n8e4ccaioOxGayGJlEk5o63yjdqyoxBCXCaE2CKECAghZsY57yIhxFYhxHYhxE2ZlNEKcinTekJ7M59541kWvrKWz7zxbMrd5uxALynPzkKCidAKqTajSZEWoZ4UjoNdCAmOQX+I45mXdF8TWLgQ77Zt9LvdeLdts7zyq97uIF5E1MKFAe5/wEfjeIkQksbxQSe2XgZ2tpHNC0m7TE+bgQXAK3onCCHygPuBucDHgS8KIT6eGfGsIVcyrRO1Js12JZLpVqhmEG02CFRX4L52oSWObL2eFHn3P2L6tVJFKx/CSERULudFZPNC0hbTk5TyAwARv177LGC7lHLn4LmrgfnA+5YLaBG5kl+RyMaf7Y5iu1qhpkvIbFAzqZSi8RMsu46u36P9oGXXTJZEEVEjES1nNEJkxUJSSGmf/U4I8TKwREq5UeO5zwMXSSm/Mfj4y8DpUsobdMa6BrgGYExl5YxH7v2p6fJ6S0pw9faaPq4V+Dz9eAORG0ZH1SgCHYcTvray55DucwHhwCFj/1kDwsGhkvKk5TSKUdlTweUI4Cy0KlMjSDL3jtMV/N4cFnlhHU17wadReDHfCR8LLlqkc/jz6Onto7Qkzf7ZnV2IffuCIUguF7KuDiqt7YERwhT5rcDTi+z3EPB68XmD/1N5Hg/Onl5EIIB0OOhpbCTf3ZdgIHOY+5UrN0kpNV0Blu0ohBB/BcZqPLVUSrnO7OtJKVcBqwCOG1MjG958zexL0DJrNlaMawWdW3cE+0GHUbDoEvofeyrha09741nNGki9BUUUD5qjopHA6rMvTVHaxBiVPRWqC7otT7hL9t6xclfh3Pm2Zk8K//dvREw5M+b8Ddv7mTNxVMrXE+ueQSy9C+H2DF+vqBB55y3I+XNTHtco6cpvFf6ufjy72nG36pcZ76+uyoo5xzIfhZTy36SUx2v8GFUSrUC4raBh8JjCYuLZ+Pvz8jVfk82OYkUkvjmn4b52IYHqCqQY9ocE5p5jyfXEygcilASAcHsQKx+w5HoK88nm8Ni3gKlCiEkEFcRCYJG9Ih0dxGtNmq/RK8KPyGpH8UhAK5w1HUe3b85pMYl8lk0G+9qTO67IOmxRFEKIS4H/BmqAp4QQ70gpLxRCjAN+JaW8WErpE0LcADwH5AG/llJmb8bUCEOr3tJn3niWPA3/xIAzP+sdxblMKJw1ZCrKqvIeRqirhb1t2scVOYEt4bFSyrVSygYpZYGUslZKeeHg8b1SyovDzntaSjlNSjlZSnmnHbIqhtFLWCvw5VCNhBxEL5y18LH1NkmUHHLJYmRRYeSxokLkksU2SaRIlmw2PSmyjERNhxTWoBfOalZ5j2Gz1iGoqw1O7CY6mYfGWvlA0NxkwTUU1qIUhcIw7048LiKHArI/kW0kIKsqEAdjlYIZ5T2izVrsbYOldwXHN1lZKMWQuyhFEYd0KjmORHI1kS3X8SyapxnOakZ5D02zltsDKx9QE7tiCKUodNAqCR6q5JhtmdSZJFHTIYX5+OachhtMjXoKoWu+UhFJijCUotDBjEqOCoVZaIWzmoGeWUtFJGUGd9Meu0UwhFIUOmRzJUeF+XRu3WHp+L4TZ8S9hl2tWDXNWioiKaPoZWVnE0pR6GBlW8FcIdfaiaZKdKkTKygIOOJep/Vf+6kv6AaCSuPArh5q2GNpcUCINWtRW4P/+isRyj9hKf6u/XaLkBRKUeiQzZUcM0EuthPNBtJRrq39ZUPKIpNEm7UKJ00mL875CnPw7LJ2F2smSlHooFUSfKCs9KjxT8QrNZ6uohipO5V4ylUjL1lhI2LdM8FaUyqvwxBKUcQhuq2gv7AwztkjC6vaiWpNpp/YupFPbN2Y80ojnnJVisJGDh3GMeeqYaVwzpmINU8NFyq0KHdkJKEURYaJzs3IxsZFYF0WttZkGipbnuvmrVzs1T3SEeueAUoQoVpTe9vgsT8jotrwqNyR+NjVCvWoJJSb4eruQRDMzah/6RVGbf3IbtFisKqdaKJJM7yTXq6Ri726Rzpi5QMQiNQK0UpiCJU7ootSFBlEKzfD4fNR+/qbNkmkz57aRt6cegq9BUVIgk2L3px6StorfSOTZq6uwHOxV/eIJ5nJX+WO6KJMTxkk13IzrMjC1qoXFU2ursDjlTixttGqQhedyV+KyJ2Fyh2Jj1IUGUTlZsROpkBEa9VcX4FbVeLE7MZFRwvByT+yea8sKkQuuARe+oeKejKIUhQZRCs3I+B0HjW5GSHCJ9ORGiprJjnfuMhG5Py5sPEj5LixMUpBz1WhiEUpigyilZuRrVFPmUIVGUxMvMZFVtR/GnGMHkVgw1/sliKnUYoiw0TnZigUibC6cZFCkQgV9aRQZDl6DYrMaFykUBhBKQqFIsvxLJqHdOVHHDOrcZFCYQRlelIoshwrGxcpFEZQikKhyAGsalykUBhBmZ4UCoVCERelKBQKhUIRF6UoFAqFQhEXWxSFEOIyIcQWIURACDEzznm7hRDvCSHeEUJszKSMCoXCOGLdMzjmfBrHlFk45nx6sLy3YqRglzN7M7AA+IWBc8+RUh60WB6FQpEiYt0ziKV3qUZAIxhbdhRSyg+klFvtuLZCoTAXsfKBYSUROub2BHtBKEYEQkr7SmMJIV4GlkgpNc1KQohdQBcggV9IKVfFGesa4BqAMZWVMx6596emy+stKcHV22v6uFbg8/TjDUSuAxxVowh0HLZJovTIZdnBuPwuRwBnYbAoudPlwOFyWS1aDKKgEOEcNjb0eHyUFsYxPrz3gf5zJxxromSpkVB+G5A+H7LfQ8DrxecN6J6XyTln7leu3CSl1HQFWPbpCSH+CozVeGqplHKdwWHOklK2CiHGAC8IIT6UUr6ideKgElkFcNyYGtnw5mspyR2PllmzsWJcK+jcuoPW/rKIYwWLLqH/sadskig9cll2MC5/dUE3ldMnA1AzqZSi8ROsFi2GwtrJ5FWMGXq8Yft+5kwZo3u+42tXDbcaDUOOG5sVxfgSyW8H/q79eHa1427dw4Fd+v1osmXOsUxRSCn/zYQxWgd/7xdCrAVmAZqKQqFQ2INcshjCfRSoRkAjjawNjxVClAghykJ/AxcQdIIrFIosQs6fi7zzFuS4sUghgr/vvEU5skcQthjuhBCXAv8N1ABPCSHekVJeKIQYB/xKSnkxUAusFUKE5HxMSvmsHfIqFIr4yPlzlWIYwdiiKKSUa4G1Gsf3AhcP/r0TOCnDoikUCoUiiqw1PSkUCoUiO1CKQqFQKBRxUYpCoVAoFHFRikKhUCgUcVGKQqFQKBRxUYpCoVAoFHFRikKhUCgUcVGKQqFQKBRxsbV6rFUIIQ4AeywYuhrI5d4YuSx/LssOuS1/LssOuS1/JmWfIKWs0XpiRCoKqxBCbNQrw5sL5LL8uSw75Lb8uSw75Lb82SK7Mj0pFAqFIi5KUSgUCoUiLkpRJIduh70cIZflz2XZIbflz2XZIbflzwrZlY9CoVAoFHFROwqFQqFQxEUpCoVCoVDERSkKgwghLhJCbBVCbBdC3GS3PMkghPi1EGK/ECLnWskKIRqFEC8JId4XQmwRQtxot0xGEUIUCiHeFEK8Oyj77XbLlApCiDwhxP8JIdbbLUsyCCF2CyHeE0K8I4TYaLc8ySKEGC2E+JMQ4kMhxAdCiE/YJovyUSRGCJEHbAPOB1qAt4AvSinft1UwgwghzgZ6gEellMfbLU8yCCHqgDop5duDPdQ3AZ/Nhc9eBPv4lkgpe4QQ+cCrwI1SytdtFi0phBDfBWYC5VLKeXbLYxQhxG5gppQyJ5PthBCPABuklL8SQriAYinlITtkUTsKY8wCtkspd0opvcBqYL7NMhlGSvkK0Gm3HKkgpdwnpXx78O9u4AOg3l6pjCGD9Aw+zB/8yamVmRCiAbgE+JXdshxNCCFGAWcDDwNIKb12KQlQisIo9UBz2OMWcmSyGkkIISYCpwBv2CyKYQbNNu8A+4EXpJQ5I/sg9wLfAwI2y5EKEnheCLFJCHGN3cIkySTgAPA/g2a/XwkhSuwSRikKRU4ghCgF/gx8R0p5xG55jCKl9EspTwYagFlCiJwx/Qkh5gH7pZSb7JYlRc6SUp4KzAWuHzTB5gpO4FTgQSnlKUAvYJtvVCkKY7QCjWGPGwaPKTLAoH3/z8DvpJRr7JYnFQbNBi8BF9ksSjKcCXxm0Na/GjhXCPFbe0UyjpSydfD3fmAtQRNyrtACtITtQP9EUHHYglIUxngLmCqEmDToVFoIPGmzTEcFgw7hh4EPpJT32C1PMgghaoQQowf/LiIYDPGhrUIlgZTyZillg5RyIsF7/m9Syi/ZLJYhhBAlg8EPDJpsLgByJupPStkGNAshpg8eOg+wLYDDadeFcwkppU8IcQPwHJAH/FpKucVmsQwjhPg98CmgWgjRAvxASvmwvVIZ5kzgy8B7g7Z+gFuklE/bJ5Jh6oBHBqPmHMDjUsqcCjHNYWqBtcF1Bk7gMSnls/aKlDTfAn43uDjdCXzNLkFUeKxCoVAo4qJMTwqFQqGIi1IUCoVCoYiLUhQKhUKhiItSFAqFQqGIi1IUCoVCoYiLUhQKhcUMVsDdJYSoHHxcMfh4os2iKRSGUIpCobAYKWUz8CCwYvDQCmCVlHK3bUIpFEmg8igUigwwWIZkE/Br4GrgZCnlgL1SKRTGUJnZCkUGkFIOCCH+E3gWuEApCUUuoUxPCkXmmAvsA3KmgqxCAUpRKBQZQQhxMsGigGcA/z7YuU+hyAmUolAoLGawAu6DBHtpNAE/AVbaK5VCYRylKBQK67kaaJJSvjD4+AHgWCHEJ22USaEwjIp6UigUCkVc1I5CoVAoFHFRikKhUCgUcVGKQqFQKBRxUYpCoVAoFHFRikKhUCgUcVGKQqFQKBRxUYpCoVAoFHH5/yDfz0XoLoRcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc_sk = GradientBoostingClassifier(criterion=\"mse\", random_state=2020)\n",
    "gbc_sk.fit(Xtrain_class, Ytrain_class)\n",
    "print(f\"Training accuracy: {gbc_sk.score(Xtrain_class, Ytrain_class)}\")\n",
    "print(f\"Test accuracy: {gbc_sk.score(Xtest_class, Ytest_class)}\")\n",
    "\n",
    "plotModel(Xtest_reg, Ytest_reg, Ytest_class, gbc_sk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "\n",
    "- Plot con los clasificadores en cada etapa (mirar en los notebooks de teoría; predict_staged).\n",
    "- Comentar clases BaseGB, RegressorGB y ClassifierGB.\n",
    "- Comentar pruebas y resultados.\n",
    "- Utilizar en conjunto real; hacer CV con n_estimators + regularización y encontrar los parámetros óptimos.\n",
    "- Plot train/test error vs number of iterations on a single dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis matemático de la pérdida logarítmica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ¿Por qué usamos la pérdida log para clasificación (adaptada a $\\pm 1$)? (binary cross-entropy, max log-likelihood)\n",
    "- ¿Por qué usamos sigmoide? Se elige primero sigmoide y luego logloss o al revés?\n",
    "- Deducción de $F_0$ (log-odds)\n",
    "- Por qué se puede usar $\\sigma(F(x))$ para recuperar la probabilidad de $y=1$.\n",
    "\n",
    "https://stats.stackexchange.com/questions/340546/likelihood-function-for-binomial-distribution-with-label-1-and-1\n",
    "\n",
    "https://stats.stackexchange.com/questions/280049/derive-a-particular-expression-for-binomial-deviance-from-elements-of-statistica\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#log-loss\n",
    "\n",
    "\\+ 2 Papers, libro de ESLR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": false,
   "autoclose": true,
   "autocomplete": false,
   "bibliofile": "bibliography.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
